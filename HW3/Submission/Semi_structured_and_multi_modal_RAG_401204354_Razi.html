<div id="812a4dbc-fe04-4b84-bdf9-390045e30806" class="cell markdown"
id="812a4dbc-fe04-4b84-bdf9-390045e30806">
<h2 id="semi-structured-rag-for-private-data">Semi-Structured RAG For
Private Data</h2>
<p>In this homework assignment, you will be delving into the realm of
<strong>Retrieval Augmented Generation (RAG)</strong>.</p>
<p>Your objective is to construct a system that leverages retrieval from
a <strong>private database</strong> consisting of PDFs. These PDFs
encapsulate a rich variety of content, including textual information,
images, and tables.</p>
<p>The challenge lies in preserving all these components while
efficiently extracting relevant data based on a user's input
question.</p>
<ul>
<li>As a first step, you will need to develop mechanisms for extracting
text from the PDFs. Also, extract textual embeddings for following
comparison with the user's input.</li>
<li>Subsequently, you should implement a process to identify and
retrieve the most pertinent information matching a user's query.</li>
<li>Because some input texts are too long, we have to summarize them,
and then use the summary of the most similar text to LLM as input.</li>
<li>Then, you will integrate this retrieved information with a Large
Language Model (LLM) to generate comprehensive and contextually relevant
responses to user queries.</li>
<li>Finally, you will apply this mechanism in a Multimodal approach,
where you convert PDF images to clip embeddings and use the input's
textual CLIP embeddings to compare with the ground truth's image
embeddings and find the most similar image to the input text.</li>
<li>As we are using Unimodal LLMs, we can not give those images to the
LLM. Hence, we use image captions to be used in LLM's input.</li>
</ul>
<p>This holistic approach ensures that no valuable information is lost,
and the system provides nuanced answers by combining both the knowledge
embedded in the PDFs and the capabilities of the LLM.</p>
<p>Instruction:</p>
<p><font color='77CC99'>Follow the Green texts and fill out the
notebook.</font></p>
<p><img src='https://drive.google.com/uc?id=1kODk16WWrn9DqvaWoEAekHRXup1djGjl' width="75%"></p>
</div>
<div id="_OrQHF5lRXYT" class="cell markdown" id="_OrQHF5lRXYT">
<h2 id="packages">Packages</h2>
</div>
<div id="8fq2qoGrDZ6-" class="cell code" data-execution_count="1"
id="8fq2qoGrDZ6-">
<div class="sourceCode" id="cb1"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>capture</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># run an `apt-get update`, just to be sure</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>apt<span class="op">-</span>get update</span></code></pre></div>
</div>
<div id="140580ef-5db0-43cc-a524-9c39e04d4df0" class="cell code"
data-execution_count="2" id="140580ef-5db0-43cc-a524-9c39e04d4df0">
<div class="sourceCode" id="cb2"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># restart kernel after first instllation</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>capture</span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>apt<span class="op">-</span>get install <span class="op">-</span>y poppler<span class="op">-</span>utils</span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>apt<span class="op">-</span>get install tesseract<span class="op">-</span>ocr</span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install pytesseract</span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># for image extraction from pdf</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> pip install PyMuPDF</span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> pip install Pillow</span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># text embedding</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> pip install <span class="op">-</span>U sentence<span class="op">-</span>transformers</span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="op">!</span> pip install transformers accelerate bitsandbytes<span class="op">&gt;=</span><span class="fl">0.39.0</span> <span class="op">-</span>q</span></code></pre></div>
</div>
<div id="x0LlYi12AkEv" class="cell code" data-execution_count="3"
id="x0LlYi12AkEv">
<div class="sourceCode" id="cb3"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="op">%%</span>capture</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="co"># Perform a full installation of unstructured and some dependencies</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>apt<span class="op">-</span>get install <span class="op">-</span>y libmagic<span class="op">-</span>dev</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>pip install unstructured[<span class="bu">all</span><span class="op">-</span>docs]</span></code></pre></div>
</div>
<div id="fw9hZJTohzhO" class="cell markdown" id="fw9hZJTohzhO">
<h1 id="0---loading-data">0 - Loading Data</h1>
</div>
<div id="e6cEOI6IL5TL" class="cell markdown" id="e6cEOI6IL5TL">
<h3 id="01---downoading-the-pdf">0.1 - Downoading the PDF</h3>
</div>
<div id="UWwLy036L-IG" class="cell code" data-execution_count="4"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="UWwLy036L-IG" data-outputId="4209a88d-040e-4277-91b0-6c1c7c0fb027">
<div class="sourceCode" id="cb4"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pathlib <span class="im">import</span> Path</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> urllib.request</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the name of the PDF file and then download them</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>file_name <span class="op">=</span> <span class="st">&quot;Dall_E_paper&quot;</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>url <span class="op">=</span> <span class="st">&quot;https://arxiv.org/pdf/2204.06125.pdf&quot;</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>file_path <span class="op">=</span> <span class="ss">f&quot;</span><span class="sc">{</span>file_name<span class="sc">}</span><span class="ss">.pdf&quot;</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>urllib.request.urlretrieve(url, file_path)</span></code></pre></div>
<div class="output execute_result" data-execution_count="4">
<pre><code>(&#39;Dall_E_paper.pdf&#39;, &lt;http.client.HTTPMessage at 0x7dfd58cd2ec0&gt;)</code></pre>
</div>
</div>
<div id="74b56bde-1ba0-4525-a11d-cab02c5659e4" class="cell markdown"
id="74b56bde-1ba0-4525-a11d-cab02c5659e4">
<h2 id="02---extract-images-and-texts">0.2 - Extract Images and
Texts</h2>
</div>
<div id="jIjR7jkHaYPd" class="cell markdown" id="jIjR7jkHaYPd">
<p>Implement mechanisms to extract images and texts from the downloaded
PDFs.</p>
</div>
<div id="__dTxER43ST0" class="cell code" data-execution_count="5"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="__dTxER43ST0" data-outputId="064f40ad-0374-44bb-a170-69a16ce3253f">
<div class="sourceCode" id="cb6"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="op">!</span>which pdftotext</span></code></pre></div>
<div class="output stream stdout">
<pre><code>/usr/bin/pdftotext
</code></pre>
</div>
</div>
<div id="tQP44Bda4ZmG" class="cell code" data-execution_count="6"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="tQP44Bda4ZmG" data-outputId="180e1f32-bdcb-450e-f8b0-e31e07c0fe2b">
<div class="sourceCode" id="cb8"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pytesseract</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(pytesseract.get_tesseract_version())</span></code></pre></div>
<div class="output stream stdout">
<pre><code>4.1.1
</code></pre>
</div>
</div>
<div id="lVZAfm2CdmSB" class="cell code" data-execution_count="7"
id="lVZAfm2CdmSB">
<div class="sourceCode" id="cb10"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Import required dependencies</span></span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> fitz</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> os</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span></code></pre></div>
</div>
<div id="9n9HKjA2an9U" class="cell markdown" id="9n9HKjA2an9U">
<h4 id="step-021-extract-and-store-images">Step 0.2.1: Extract and Store
Images</h4>
</div>
<div id="RkdJijDrd0DR" class="cell code" data-execution_count="8"
id="RkdJijDrd0DR">
<div class="sourceCode" id="cb11"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Open PDF file</span></span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>pdf_file <span class="op">=</span> fitz.<span class="bu">open</span>(file_path)</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Calculate number of pages in PDF file</span></span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>page_nums <span class="op">=</span> <span class="bu">len</span>(pdf_file)</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a><span class="co"># Create an empty list to store images information</span></span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>images_list <span class="op">=</span> []</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Extract all images information from each page</span></span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> page_num <span class="kw">in</span> <span class="bu">range</span>(page_nums):</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    page_content <span class="op">=</span> pdf_file[page_num]</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    images_list.extend(page_content.get_images(full<span class="op">=</span><span class="va">True</span>))  <span class="co"># Ensure full image info is retrieved</span></span></code></pre></div>
</div>
<div id="ZrYARvGQd70n" class="cell code" data-execution_count="9"
id="ZrYARvGQd70n">
<div class="sourceCode" id="cb12"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> io</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>images_path <span class="op">=</span> <span class="st">&quot;./images/&quot;</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>Path(images_path).mkdir(parents<span class="op">=</span><span class="va">True</span>, exist_ok<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Save all the extracted images and convert to PNG if necessary</span></span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> i, image_info <span class="kw">in</span> <span class="bu">enumerate</span>(images_list, start<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    xref <span class="op">=</span> image_info[<span class="dv">0</span>]</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>    base_image <span class="op">=</span> pdf_file.extract_image(xref)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>    image_bytes <span class="op">=</span> base_image[<span class="st">&#39;image&#39;</span>]</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>    image_ext <span class="op">=</span> base_image[<span class="st">&#39;ext&#39;</span>]</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert .ppm images to .png</span></span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> image_ext.lower() <span class="op">==</span> <span class="st">&#39;ppm&#39;</span>:</span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>        image_ext <span class="op">=</span> <span class="st">&#39;png&#39;</span></span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> Image.<span class="bu">open</span>(io.BytesIO(image_bytes))</span>
<span id="cb12-17"><a href="#cb12-17" aria-hidden="true" tabindex="-1"></a>        image_bytes <span class="op">=</span> io.BytesIO()</span>
<span id="cb12-18"><a href="#cb12-18" aria-hidden="true" tabindex="-1"></a>        image.save(image_bytes, <span class="bu">format</span><span class="op">=</span><span class="st">&#39;PNG&#39;</span>)</span>
<span id="cb12-19"><a href="#cb12-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-20"><a href="#cb12-20" aria-hidden="true" tabindex="-1"></a>    image_name <span class="op">=</span> <span class="ss">f&quot;</span><span class="sc">{</span>file_name<span class="sc">}</span><span class="ss">_</span><span class="sc">{</span>i<span class="sc">}</span><span class="ss">.</span><span class="sc">{</span>image_ext<span class="sc">}</span><span class="ss">&quot;</span></span>
<span id="cb12-21"><a href="#cb12-21" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> <span class="bu">open</span>(os.path.join(images_path, image_name), <span class="st">&#39;wb&#39;</span>) <span class="im">as</span> image_file:</span>
<span id="cb12-22"><a href="#cb12-22" aria-hidden="true" tabindex="-1"></a>        image_file.write(image_bytes.getbuffer() <span class="cf">if</span> <span class="bu">isinstance</span>(image_bytes, io.BytesIO) <span class="cf">else</span> image_bytes)</span></code></pre></div>
</div>
<div id="KAiA72BUdTY5" class="cell markdown" id="KAiA72BUdTY5">
<h3 id="step-022-extract-and-store-texts-from-pdf-content">Step 0.2.2:
Extract and Store Texts From PDF Content</h3>
</div>
<div id="u1_67ZhHhokN" class="cell code" data-execution_count="10"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:187,&quot;referenced_widgets&quot;:[&quot;132b7825e4c6411d8887817bb1cab484&quot;,&quot;f47ea81894b64e518eeb6902b824020f&quot;,&quot;82c38d26d9e440879cfc46cd6a2c7b32&quot;,&quot;c3c0963de5cf4630889e17ef9b6d4be2&quot;,&quot;0de2cf510ec244348dc72e3c15a4755f&quot;,&quot;e4325c71f420470cabaca14fcb6ae859&quot;,&quot;09bf5bc9e85c43c4bfa4e0828041b6ce&quot;,&quot;dbec71e9cb5e446da6d6eb9feedd7683&quot;,&quot;1b77ab8ca96b46ea810a172ab5de36d2&quot;,&quot;d430f61ba1e4482c97eee6013d65811a&quot;,&quot;a4077fec0a4644eb8775ceb9ffec04bb&quot;,&quot;beb04afb6d0f4c19b5a097bac8c937fd&quot;,&quot;1afff240e764470e8c296e3a909b23c1&quot;,&quot;ddeaf7cb7e2a41e5a3c3fbf73e0be0bd&quot;,&quot;91cadf0b627f48ae9bc3585353e08646&quot;,&quot;8f9b2ea7e5724a3a9051e9a91edfd24c&quot;,&quot;4eefcad140ca4502bac6ebaf0bf7e045&quot;,&quot;d8555987870d40acaf22f240ead197ad&quot;,&quot;b7c291337a954769a0805a75550a7020&quot;,&quot;fed6bbb7fcb04804837f272f82a1f1a4&quot;,&quot;913b0f5580f84c898403ac5e30e9fab2&quot;,&quot;1e21bcb482374328bed5dde4ed5d9478&quot;,&quot;c6a72890eed34b4ca98f9b7abe760c33&quot;,&quot;a096bca298214217a16771bcf9cd9aa4&quot;,&quot;6580879aedc6452fa5cd006170cd72c2&quot;,&quot;1571a711266f443ba4eca8fbb510430e&quot;,&quot;69f06738f575426f81551ce8cfe60774&quot;,&quot;94bff95606d24af5888f68802ef1c5b9&quot;,&quot;c63449939d47455bb4febdd80ce40064&quot;,&quot;f412c0e629ee4fcf8d5bef0dd261cb43&quot;,&quot;299dabf76bbe4167ab49977cefe6738b&quot;,&quot;63fc95eafa134eb68303c1d2a7947352&quot;,&quot;b78ac853b239453eb636d9b718678467&quot;]}"
id="u1_67ZhHhokN" data-outputId="8c35cbd8-da6b-47f5-cc2b-86a08eb33308">
<div class="sourceCode" id="cb13"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> lxml <span class="im">import</span> html</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> pydantic <span class="im">import</span> BaseModel</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> typing <span class="im">import</span> Any, Optional</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> unstructured.partition.pdf <span class="im">import</span> partition_pdf</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Define the paths</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>path <span class="op">=</span> <span class="st">&#39;./&#39;</span></span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>image_output_dir_path <span class="op">=</span> <span class="st">&#39;./images/&#39;</span>  <span class="co"># Path where extracted images are stored</span></span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a><span class="co"># Specify the paths to the Poppler and Tesseract installations</span></span>
<span id="cb13-11"><a href="#cb13-11" aria-hidden="true" tabindex="-1"></a>poppler_path <span class="op">=</span> <span class="st">&#39;/usr/bin/&#39;</span>  <span class="co"># Replace with the correct path</span></span>
<span id="cb13-12"><a href="#cb13-12" aria-hidden="true" tabindex="-1"></a>tesseract_path <span class="op">=</span> <span class="st">&#39;/usr/bin/tesseract&#39;</span>  <span class="co"># Replace with the correct path</span></span>
<span id="cb13-13"><a href="#cb13-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb13-14"><a href="#cb13-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Get elements from the PDF</span></span>
<span id="cb13-15"><a href="#cb13-15" aria-hidden="true" tabindex="-1"></a>raw_pdf_elements <span class="op">=</span> partition_pdf(</span>
<span id="cb13-16"><a href="#cb13-16" aria-hidden="true" tabindex="-1"></a>    filename<span class="op">=</span><span class="st">&quot;./Dall_E_paper.pdf&quot;</span>,</span>
<span id="cb13-17"><a href="#cb13-17" aria-hidden="true" tabindex="-1"></a>    extract_images_in_pdf<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-18"><a href="#cb13-18" aria-hidden="true" tabindex="-1"></a>    infer_table_structure<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb13-19"><a href="#cb13-19" aria-hidden="true" tabindex="-1"></a>    chunking_strategy<span class="op">=</span><span class="st">&quot;by_title&quot;</span>,</span>
<span id="cb13-20"><a href="#cb13-20" aria-hidden="true" tabindex="-1"></a>    max_characters<span class="op">=</span><span class="dv">2000</span>,</span>
<span id="cb13-21"><a href="#cb13-21" aria-hidden="true" tabindex="-1"></a>    new_after_n_chars<span class="op">=</span><span class="dv">1900</span>,</span>
<span id="cb13-22"><a href="#cb13-22" aria-hidden="true" tabindex="-1"></a>    combine_text_under_n_chars<span class="op">=</span><span class="dv">1000</span>,</span>
<span id="cb13-23"><a href="#cb13-23" aria-hidden="true" tabindex="-1"></a>    image_output_dir_path<span class="op">=</span>image_output_dir_path,</span>
<span id="cb13-24"><a href="#cb13-24" aria-hidden="true" tabindex="-1"></a>    tesseract_path<span class="op">=</span>tesseract_path,</span>
<span id="cb13-25"><a href="#cb13-25" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb14"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;132b7825e4c6411d8887817bb1cab484&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb15"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;beb04afb6d0f4c19b5a097bac8c937fd&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb16"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;c6a72890eed34b4ca98f9b7abe760c33&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Some weights of the model checkpoint at microsoft/table-transformer-structure-recognition were not used when initializing TableTransformerForObjectDetection: [&#39;model.backbone.conv_encoder.model.layer3.0.downsample.1.num_batches_tracked&#39;, &#39;model.backbone.conv_encoder.model.layer2.0.downsample.1.num_batches_tracked&#39;, &#39;model.backbone.conv_encoder.model.layer4.0.downsample.1.num_batches_tracked&#39;]
- This IS expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing TableTransformerForObjectDetection from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
</code></pre>
</div>
</div>
<div id="5f660305-e165-4b6c-ada3-a67a422defb5" class="cell code"
data-execution_count="11"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="5f660305-e165-4b6c-ada3-a67a422defb5"
data-outputId="6e64b6dd-ca13-4e94-bf48-4369ba6b094f">
<div class="sourceCode" id="cb18"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>text_elements <span class="op">=</span> []</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> element <span class="kw">in</span> raw_pdf_elements:</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="st">&quot;unstructured.documents.elements.CompositeElement&quot;</span> <span class="kw">in</span> <span class="bu">str</span>(<span class="bu">type</span>(element)):</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>      text_elements.append(<span class="bu">str</span>(element))</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="bu">len</span>(text_elements))</span></code></pre></div>
<div class="output stream stdout">
<pre><code>39
</code></pre>
</div>
</div>
<div id="4Vn9zQcvJNXF" class="cell code" data-execution_count="12"
id="4Vn9zQcvJNXF">
<div class="sourceCode" id="cb20"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a>long_text_ind <span class="op">=</span> <span class="dv">10</span></span></code></pre></div>
</div>
<div id="i9zIZEN1JRV6" class="cell code" data-execution_count="13"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:143}"
id="i9zIZEN1JRV6" data-outputId="c89ed5d5-6fa5-4f1c-8075-4b4da2d3df1e">
<div class="sourceCode" id="cb21"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a>text_elements[long_text_ind]</span></code></pre></div>
<div class="output execute_result" data-execution_count="13">
<div class="sourceCode" id="cb22"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;type&quot;</span><span class="fu">:</span><span class="st">&quot;string&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div id="nVtv83Y-GXp1" class="cell markdown" id="nVtv83Y-GXp1">
<p>Because some texts are too long, we have to summarize them at
first</p>
</div>
<div id="BVVjUuStGWXd" class="cell code" data-execution_count="14"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:265,&quot;referenced_widgets&quot;:[&quot;2e263fdfe8ae48bdaff0f7d4cd6ba089&quot;,&quot;7e13f8e18a51413194bf922e04e03ee2&quot;,&quot;2e60ff8c94414a61bcb09bce4355a739&quot;,&quot;1e6e6002f3da42dd91d26199a4f12f4c&quot;,&quot;dd12377a69ed4a269d822b185931d0d9&quot;,&quot;3dd3c63fe5cc415b8f2899482c736318&quot;,&quot;8181be74b4544d5090d90b7257d19a2d&quot;,&quot;a64e9f928a3a4d7d9b284cde0e82a424&quot;,&quot;b8ec2e98affb4bb29b15b7474a7239ad&quot;,&quot;1a33d9f5e7234db8986c597be3ac7301&quot;,&quot;0c389c3e4dc840c5aa7f35d8fb2a107b&quot;,&quot;f834340199e542ab8c194374aef550d4&quot;,&quot;c2a0a71ac609430386db5d3341c0dff1&quot;,&quot;9a0db1ac208c438ebec15c48dc311e28&quot;,&quot;636f8932596c4d78b4b4980620843533&quot;,&quot;6f92d41ada86457fbc1b31a036e3e356&quot;,&quot;efed1b17d117458db24fdd6a5e19ae7c&quot;,&quot;9ca464c529da495d80cfb503e2ab99f0&quot;,&quot;163c33bfc4c644b59250d77d53241c2c&quot;,&quot;a9ea4d8f19f441b9975cc2895f92ae03&quot;,&quot;efb59ce606d74f748afd6cb63e08fd26&quot;,&quot;a32a25aefc4040378c1fc449b0357410&quot;,&quot;07b66cb3ad7a40d188224e22442be9c1&quot;,&quot;6e5e77df0a2140ddb0e163c0d57aed05&quot;,&quot;49a220dbe036467d98f7ec717acf3aad&quot;,&quot;fcf90a7936a746b2a7bcb7d3368a66b0&quot;,&quot;eed00b14cd024c7b8f7e842705018b99&quot;,&quot;2e4b098cfbd7487f8965b55859899ecc&quot;,&quot;fdc110a6c00b407480019e146c51c7e9&quot;,&quot;dabe769f6fc24f50b32fa04fe287d1e4&quot;,&quot;165ac89a72c54cfcab0107d457bd3956&quot;,&quot;e8aa90844b6b4c0a8529d04316ea0e67&quot;,&quot;530ab73ea8a743618956e1eac8d8f3d9&quot;,&quot;35311ef1f3684be29a17a9a72240dafe&quot;,&quot;5d73be3112214f0abfa5d684b294daad&quot;,&quot;33449200f4bc482ba5866bf352455113&quot;,&quot;72d7e217a4ed4ad085d0eea98c27462f&quot;,&quot;e3ddb6f08cc44de79ca9fca77641cd6e&quot;,&quot;6c29867dd4ba4dd5968101c9ae7924e8&quot;,&quot;45377334707c40c7831fe1489dc37550&quot;,&quot;d5ddd670f315455fb0f54e14942fdb4f&quot;,&quot;8028ea30ed3b45c8b3c1cc194e716c32&quot;,&quot;6d9ce556ec634c3f9c8e8858a2c069d2&quot;,&quot;414a89b269194f1ea34b00ac0b3cfec2&quot;,&quot;a4f76675d63848208d3a35caf0697488&quot;,&quot;a29553cfa47c482ba24ca849c0d0fab0&quot;,&quot;f9e18b22ad574e529170a0eb9f26abb6&quot;,&quot;b62e565cc1804fa283c522096a56e65a&quot;,&quot;760d940505444a61a08a5b64735b1f4d&quot;,&quot;749462c79116429a82e1ef0f0bd7d41d&quot;,&quot;025895d7384a42cb97134fe0ced9b37b&quot;,&quot;787f660d3daa4c0c9099f190f29424ff&quot;,&quot;cbe974de7ce74dd68eb534a15004b92d&quot;,&quot;32b699123b36474085199c74a612576c&quot;,&quot;e5f699a3062c42f6bf52b03a21b17d26&quot;,&quot;997899b5816d4f68be0b1e9c29ee0a84&quot;,&quot;b9472be776654c2498bb9b387921e212&quot;,&quot;28bcd01cdf2142609ca7a1e3e5098e27&quot;,&quot;c6b780ef92f64292b9699eddf4d743f1&quot;,&quot;e0694b5ef8de4045851d48c50d170280&quot;,&quot;560b771d03114d63b61e7869a48e8e42&quot;,&quot;adda567586874c8f9fa11c27b0ce003d&quot;,&quot;d831d90bae244f8eba411838caff3b7a&quot;,&quot;a38704b2f1174341bb1901ba07893a20&quot;,&quot;8f08cd95c2194f1e8b5842a812175d8e&quot;,&quot;5a8a472ad1a5486a943ac0ea66320367&quot;]}"
id="BVVjUuStGWXd" data-outputId="08ce5e87-3147-4149-a4e0-6c7c64dc7ef3">
<div class="sourceCode" id="cb23"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>summarizer <span class="op">=</span> pipeline(<span class="st">&quot;summarization&quot;</span>, model<span class="op">=</span><span class="st">&quot;facebook/bart-large-cnn&quot;</span>)</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>summarized_text_elements <span class="op">=</span> summarizer(text_elements , max_length<span class="op">=</span><span class="dv">100</span>, do_sample<span class="op">=</span><span class="va">False</span>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb24"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;2e263fdfe8ae48bdaff0f7d4cd6ba089&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb25"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;f834340199e542ab8c194374aef550d4&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb26"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;07b66cb3ad7a40d188224e22442be9c1&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb27"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;35311ef1f3684be29a17a9a72240dafe&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb28"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;a4f76675d63848208d3a35caf0697488&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb29"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;997899b5816d4f68be0b1e9c29ee0a84&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>Your max_length is set to 100, but your input_length is only 37. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer(&#39;...&#39;, max_length=18)
Your max_length is set to 100, but your input_length is only 50. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer(&#39;...&#39;, max_length=25)
</code></pre>
</div>
</div>
<div id="bfUHd2zpJy_4" class="cell code" data-execution_count="15"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="bfUHd2zpJy_4" data-outputId="53e4b5b5-6858-425c-8cdc-2397189f22b1">
<div class="sourceCode" id="cb31"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a>summarized_text_elements[long_text_ind]</span></code></pre></div>
<div class="output execute_result" data-execution_count="15">
<pre><code>{&#39;summary_text&#39;: &#39;It is also possible to blend two images x1 and x2 for variations. To do this, we rotate between their CLIP embeddings zi1 and zi2 using spherical interpolation. A key advantage of using CLIP compared to other models for image representations is that it embeds images and text to the same latent space.&#39;}</code></pre>
</div>
</div>
<div id="t0-Vp95ziTp3" class="cell markdown" id="t0-Vp95ziTp3">
<h1 id="1---unimodal-rag">1 - Unimodal RAG</h1>
</div>
<div id="oVLZs4eKifj-" class="cell markdown" id="oVLZs4eKifj-">
<h2 id="11---loading-true-text-data-as-embeded-vectors">1.1 - Loading
True Text Data as Embeded Vectors</h2>
</div>
<div id="W_Fxk_U3jPoS" class="cell markdown" id="W_Fxk_U3jPoS">
<p>In this section, we should convert the text data into embedding
vectors and store them. Hence, in the following step. having an input,
by comparing we can find out the most similar fact with the input.</p>
<p>We use this model for <a
href="https://huggingface.co/sentence-transformers/all-MiniLM-L12-v2">Text-Embedding</a></p>
</div>
<div id="iFpBR_k3jtvL" class="cell code" data-execution_count="16"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:465,&quot;referenced_widgets&quot;:[&quot;89d398fe825e4524810e361cefc4e4d0&quot;,&quot;28d7913cca9e482184fa22acf1636bc4&quot;,&quot;9a35783d2e2244c481f86a26e0e0899d&quot;,&quot;1438aaea2efc420283073352e6cbbbe2&quot;,&quot;6742f92150dd4af082ebfd66926826eb&quot;,&quot;0d9449f5bb6043faabbeda7ffdfad461&quot;,&quot;076528e9f6bf4ac3bc6a851e406d03bb&quot;,&quot;a8fb55492617494cb0c70f427d3a6bf5&quot;,&quot;8a84f910184d4c55a2da0dea65094ea7&quot;,&quot;e18b5544ef1845139b6b02e3a81b2850&quot;,&quot;4cfe4c9fe5fc4544be3af064d6a35b33&quot;,&quot;98353409af78441bab8bd9a93f15ad34&quot;,&quot;73ab28e70dd54e4a850ed53a9abc220f&quot;,&quot;10ff2f43ba7d4609b95d64b3f36694f9&quot;,&quot;1717a321478b4b84ae4798d5c6c24484&quot;,&quot;ea6004bb4d69492fbfac38fa2354c2b8&quot;,&quot;f9c692687ca54cb2a840203c6bb60b80&quot;,&quot;06fd09340ea0421ba107150078cdf3b3&quot;,&quot;3246538d0f9846f38e3b0140475138a0&quot;,&quot;3e89dd4d3b2a4359ac289b5c58c47b16&quot;,&quot;8f433c58f6dc42719d442db3d44546a3&quot;,&quot;9aece9fd4f764e0b9c8176f2ec8e297d&quot;,&quot;5710c1ed16054a2bb7a3d4612c2529be&quot;,&quot;f854c561999a4792be836297c7c10a5d&quot;,&quot;1a67e9caf0e04b47bf21ea255c104eda&quot;,&quot;692982d5f3fb4cd888bbc38914ae7209&quot;,&quot;41abab03dd574c2db06d42b1186b2b4b&quot;,&quot;26629c504e89483c954234d2382a8d61&quot;,&quot;1d8929f7ca2b4ee2bba04f446142fcff&quot;,&quot;55ffcd7525b24ef3890af0963eaa9aef&quot;,&quot;12c9da2dbeb34aedbe80e38ee6a15063&quot;,&quot;716f2445ee374da28d259a728d549514&quot;,&quot;9437a07123d74a5a9d64c9ecc7190502&quot;,&quot;b9ca03bb51c845a9bb18ced959050f64&quot;,&quot;92b3281ca3a5407ba1dc0fa336c20a4c&quot;,&quot;29d2fee31b6c4cd19e2b3ffa34cece70&quot;,&quot;fde85b26afcd4ef18af44535c0fbb0f5&quot;,&quot;119f7a442311430895af719f8f587014&quot;,&quot;73d9001a91a34a89ba048095de0774c8&quot;,&quot;a81f76923b784145afae5f9023d92189&quot;,&quot;3790c8c41c294ae4a7b8d30d6647b569&quot;,&quot;200d4369ba4d46e0aa018dc87a201513&quot;,&quot;5ddfaf66ec4542528fa8a5bf4a76b5af&quot;,&quot;f7ffd272105844f8b7b876a156a91beb&quot;,&quot;2aeb2bfea7754733a503d9edb20e2382&quot;,&quot;c20002475c2b493cb3b71afe1fd6bace&quot;,&quot;6c7fbccdff6a49eda2657cfa66a7f01b&quot;,&quot;443700483c354f36be88cc99c9ebba47&quot;,&quot;716ccd16d9d449f796cd2d7c0caac6a5&quot;,&quot;55e31b106cdf45afbfd681287098da73&quot;,&quot;814a10cefffa49ab9f84b2f87c1ba9dd&quot;,&quot;beba08f85cda4fd4a4cae506403c56c9&quot;,&quot;4c67a6cf45004f66b78611cfcd38f7fa&quot;,&quot;4012a5110398495394fe8efa151d420d&quot;,&quot;ae9a5147c4ad4f65b87e2d3cf0e360d1&quot;,&quot;3a01f0e205104b03be45812d519e3173&quot;,&quot;c6f72d3feb584f5984c72e35ec78ed54&quot;,&quot;518dc1059685484687b7d4eef211ec99&quot;,&quot;f04efa3aa8904ab4a7083b6d648a2bd6&quot;,&quot;a82ac4b964a64589a6b59d76ff523751&quot;,&quot;511ddd9d96ee4d27936ff680262f2c37&quot;,&quot;84ceb37949904319add985216afe4bbc&quot;,&quot;657080f7859d4a50b487d7e07d7d314c&quot;,&quot;fe581007b29c4cf9a84bd4deafef4519&quot;,&quot;dec0fe040c634d138916a544e1dbb81f&quot;,&quot;835c2507795b487b8e897bf1747a4dc4&quot;,&quot;914c850283e64ea3a510660a3c0dab09&quot;,&quot;590a80c574bf4ee4953c06c13155da26&quot;,&quot;6e5dbddb83c24df586fae7007b885e8c&quot;,&quot;12264951bf5444108fab6e32babe9d67&quot;,&quot;38cd7a8b0ef642cc97c4f50e08bd2025&quot;,&quot;3e5bd504186844f598e8cc4650be5e52&quot;,&quot;556cba132b574aeabaffa93673ad9568&quot;,&quot;99dbe40f99cb47aeb7939dd90a3b5f31&quot;,&quot;5ecbd60461a34b9490c07f4f38650fb2&quot;,&quot;d846e81bb35c4b3bbbd5a2b098dcb190&quot;,&quot;171cbdfc3f734ad19eb3a607e136852f&quot;,&quot;ddc1cf615c8e46ef8594bedd0a54ba98&quot;,&quot;04a3cfa44068406b8062eb5f43ec0506&quot;,&quot;32d700d41abb4f71873d8b2d68cfc872&quot;,&quot;846831953d2f4430812cdaa74e24094b&quot;,&quot;82befd2c2d50472c863210df4c754958&quot;,&quot;fe5ea454f06f484f8e19995669e2954b&quot;,&quot;b8ba3ed6033b4c6aad35d7eaed4ab24a&quot;,&quot;af35731d6cb24a698c2b2e11fcfae845&quot;,&quot;98456aaedbf241e78aebd25fd46bb362&quot;,&quot;2b22cdff4637441c8d9c25354bbb5c9b&quot;,&quot;bbf1aa20c03e47c794f14e8aa3e13054&quot;,&quot;2a5f8f459c614003916decc5bdfc95a8&quot;,&quot;8d195bff629b46168e05de2ace1762ec&quot;,&quot;ce27ce3c99314df485b518251057bbd5&quot;,&quot;f3b1771b8c99470da9ce061ec57c20a4&quot;,&quot;4a02dee5fc224bbfbfd07e7ae6f852f5&quot;,&quot;0f3b34674ef84622bf6328eea5345aa6&quot;,&quot;b04d481be20b4579b353a752c42061a5&quot;,&quot;407e8ee79cc94c77a55c12dc79bf6349&quot;,&quot;3244884295c64ecbb47e6ab7e02058dd&quot;,&quot;b2a3f1e9580e45209b0aeeb147ee97a8&quot;,&quot;37331740b22f4654a3e525e5b74a0371&quot;,&quot;8d4633eb0c184784ac1c6ff823fec68a&quot;,&quot;17c9b005040344fab59af989910119cd&quot;,&quot;023aafbac6594e7690c42b402cf5c214&quot;,&quot;b7563ce46d324bf68e9bbe6fad4e2489&quot;,&quot;f36a7a3106c44100964ec750dfeb41b7&quot;,&quot;389f86d119c04aa78c3153748e462b47&quot;,&quot;6dbc8fde92e24adfb34f3fff9cb3e6b8&quot;,&quot;f896081d20154a2eb555983609fc6530&quot;,&quot;0f9191488c2d45c4bd220c5506a7571b&quot;,&quot;23f341b5168945ce9f64923cc7c27f5e&quot;,&quot;2ee4d49b49fe4019a9d76aa28bc002c0&quot;,&quot;f53e576b3b5c49fe84a2c2bebd6823af&quot;,&quot;75c9aa09569045068b10da4befa1dca3&quot;,&quot;dbd152267bf9453e9071d3f383e5d72e&quot;,&quot;a32c8dd910554291b7bf717b68768919&quot;,&quot;6ccdca7decb74ee1b00fa12f991a8a3f&quot;,&quot;50906bd5fbe847889559ef33fd4e231d&quot;,&quot;48b5291321224b3a9e4b993115ff721a&quot;,&quot;7d4ee309e5fc4424a15406fdb24d35a4&quot;,&quot;c7e404ab3a304df7a0f4257b20323fd3&quot;,&quot;48791508c0794559b9415cd4b04b0095&quot;,&quot;98dc47821f784c1bb00c1593b9801e51&quot;,&quot;218d8283910f4a0ea161ce49e688e936&quot;,&quot;ec604f5735b34e4e80072823510b7001&quot;,&quot;0d1d4a1e12864c6ebdf4dfcb159df629&quot;,&quot;c6605b83051a4022be36ff5626a12598&quot;,&quot;d5a45281341749f7842d1af3ec3f4e9d&quot;,&quot;c5570c664fdf4bca8d9bc0179c7c5120&quot;,&quot;ec58a2ae3e464c3894755e8064bd42aa&quot;,&quot;a3f1b6d81d5a4db5bbed46694c79a1a5&quot;,&quot;a0eb552bec5e47ed8e7145722183b10d&quot;,&quot;93b102de0c464b3eab2bffd7a0784481&quot;,&quot;2b8b20993b1c4e7ca67d14ef6c540731&quot;,&quot;7cdfe4ecbcdc4b0c89aad593c4f093e3&quot;,&quot;77de189f13014d44a9f070baf445519a&quot;,&quot;71f495583b3d4f10a910754389286e19&quot;,&quot;554a7739d9844d2d81460bd3e0a5c8bd&quot;,&quot;fcf64bd805a740efb9881f857219b8e8&quot;,&quot;10a2f38275ca485b81b251b51e219e08&quot;,&quot;89ac0eedf9344151a58066985a7da9c5&quot;,&quot;1327c1ad58874e519e45f490ef6d8721&quot;,&quot;476b7419f4a14bb199be8ececc3df923&quot;,&quot;ff28a115a82c494c81b5cf5547cd031f&quot;,&quot;ba825162e35d4fb6811f7912a3b27b47&quot;,&quot;fff355cdff0f4277be8e3b1f05ff9daf&quot;,&quot;736bfadc4c204734b6e4a29fbade3183&quot;,&quot;989f40c4287743adbd5206e8087bfa6a&quot;,&quot;5e3fcdbc1e404e738a3b29cdb9240078&quot;,&quot;9aa33c9bd0fb4734bd84edccd3026d3a&quot;,&quot;8d73bf38f3a845edb4964e2c299ac615&quot;,&quot;e439e9608fca4b1b80e4f91fc4d89df5&quot;,&quot;2765081fc3d740138b8b83cf44d7967f&quot;,&quot;99bd12604563478f9a97d56bfe1ca295&quot;,&quot;43925ccdb0e6444186124ea3f41a8002&quot;,&quot;fef713657d9f40b5bc7c72350c5cfef1&quot;]}"
id="iFpBR_k3jtvL" data-outputId="10b29846-1ef9-45d0-a014-21e559a0b390">
<div class="sourceCode" id="cb33"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sentence_transformers <span class="im">import</span> SentenceTransformer, util</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>text_emb_model <span class="op">=</span> SentenceTransformer(<span class="st">&#39;sentence-transformers/all-MiniLM-L6-v2&#39;</span>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb34"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;89d398fe825e4524810e361cefc4e4d0&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb35"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;98353409af78441bab8bd9a93f15ad34&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb36"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5710c1ed16054a2bb7a3d4612c2529be&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb37"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;b9ca03bb51c845a9bb18ced959050f64&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb38"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;2aeb2bfea7754733a503d9edb20e2382&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb39"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;3a01f0e205104b03be45812d519e3173&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb40"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;914c850283e64ea3a510660a3c0dab09&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb41"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;ddc1cf615c8e46ef8594bedd0a54ba98&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb42"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;2a5f8f459c614003916decc5bdfc95a8&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb43"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb43-1"><a href="#cb43-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8d4633eb0c184784ac1c6ff823fec68a&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb44"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb44-1"><a href="#cb44-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;f53e576b3b5c49fe84a2c2bebd6823af&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb45"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;218d8283910f4a0ea161ce49e688e936&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb46"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb46-1"><a href="#cb46-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;7cdfe4ecbcdc4b0c89aad593c4f093e3&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb47"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb47-1"><a href="#cb47-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;fff355cdff0f4277be8e3b1f05ff9daf&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div id="lRpeenvCmTqy" class="cell code" data-execution_count="17"
id="lRpeenvCmTqy">
<div class="sourceCode" id="cb48"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>text_embeddings <span class="op">=</span> text_emb_model.encode(text_elements, convert_to_tensor<span class="op">=</span><span class="va">True</span>)</span></code></pre></div>
</div>
<div id="BEG_md7MmxYC" class="cell markdown" id="BEG_md7MmxYC">
<p>Now, we have all our crucial embeddings. Thus, if we have a new
input, we know that we should compare the input's embeddings with the
text_embeddings element and find the closest one.</p>
</div>
<div id="TsKmRTsqnIi-" class="cell markdown" id="TsKmRTsqnIi-">
<h2 id="12---unimodal-semi-structured-rag">1.2 - Unimodal
Semi-Structured RAG</h2>
</div>
<div id="Iq1Ua_TNo9US" class="cell markdown" id="Iq1Ua_TNo9US">
<h3 id="step-121-most-similar-ground-truth-text-ectraction">Step 1.2.1:
Most Similar Ground Truth Text Ectraction</h3>
</div>
<div id="JJdhgBzinObQ" class="cell markdown" id="JJdhgBzinObQ">
<p>At the fist step, for any given input, we have to have evaluation
functions to find the closest embedding vector to the input vectors. We
use the Cosine similarity for this operation.</p>
<p><font color='77CC99'>Write a function "text_embedding_similarity" to
convert input texts to embedded vector and then returns the similarity
between the input text and any of the ground truth texts.</font></p>
</div>
<div id="bSMJ8d40nOMK" class="cell code" data-execution_count="18"
id="bSMJ8d40nOMK">
<div class="sourceCode" id="cb49"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb49-1"><a href="#cb49-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb49-2"><a href="#cb49-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-3"><a href="#cb49-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> get_similarity(embeddings_1, embeddings_2, device):</span>
<span id="cb49-4"><a href="#cb49-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Convert lists of embeddings to tensors if necessary</span></span>
<span id="cb49-5"><a href="#cb49-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(embeddings_1, <span class="bu">list</span>):</span>
<span id="cb49-6"><a href="#cb49-6" aria-hidden="true" tabindex="-1"></a>        embeddings_1 <span class="op">=</span> torch.stack(embeddings_1).to(device)</span>
<span id="cb49-7"><a href="#cb49-7" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> <span class="bu">isinstance</span>(embeddings_2, <span class="bu">list</span>):</span>
<span id="cb49-8"><a href="#cb49-8" aria-hidden="true" tabindex="-1"></a>        embeddings_2 <span class="op">=</span> torch.stack(embeddings_2).to(device)</span>
<span id="cb49-9"><a href="#cb49-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-10"><a href="#cb49-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Normalize the embeddings</span></span>
<span id="cb49-11"><a href="#cb49-11" aria-hidden="true" tabindex="-1"></a>    embeddings_1 <span class="op">=</span> embeddings_1 <span class="op">/</span> embeddings_1.norm(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb49-12"><a href="#cb49-12" aria-hidden="true" tabindex="-1"></a>    embeddings_2 <span class="op">=</span> embeddings_2 <span class="op">/</span> embeddings_2.norm(dim<span class="op">=-</span><span class="dv">1</span>, keepdim<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb49-13"><a href="#cb49-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-14"><a href="#cb49-14" aria-hidden="true" tabindex="-1"></a>    similarity_matrix <span class="op">=</span> (embeddings_1 <span class="op">@</span> embeddings_2.T)</span>
<span id="cb49-15"><a href="#cb49-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb49-16"><a href="#cb49-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> similarity_matrix.cpu().detach().numpy() <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> similarity_matrix.detach().numpy()</span></code></pre></div>
</div>
<div id="EOoxZJXgZES9" class="cell code" data-execution_count="19"
id="EOoxZJXgZES9">
<div class="sourceCode" id="cb50"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb50-1"><a href="#cb50-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb50-2"><a href="#cb50-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-3"><a href="#cb50-3" aria-hidden="true" tabindex="-1"></a>device <span class="op">=</span> torch.device(<span class="st">&quot;cuda&quot;</span> <span class="cf">if</span> torch.cuda.is_available() <span class="cf">else</span> <span class="st">&quot;cpu&quot;</span>)</span>
<span id="cb50-4"><a href="#cb50-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb50-5"><a href="#cb50-5" aria-hidden="true" tabindex="-1"></a>torch.set_default_device(device)</span></code></pre></div>
</div>
<div id="ZOO-eSuSnOHe" class="cell code" data-execution_count="20"
id="ZOO-eSuSnOHe">
<div class="sourceCode" id="cb51"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> text_embedding_similarity(input_text, text_embeddings, text_emb_model):</span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate embedding for the input text</span></span>
<span id="cb51-3"><a href="#cb51-3" aria-hidden="true" tabindex="-1"></a>    input_text_emb <span class="op">=</span> text_emb_model.encode([input_text], convert_to_tensor<span class="op">=</span><span class="va">True</span>)[<span class="dv">0</span>]</span>
<span id="cb51-4"><a href="#cb51-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb51-5"><a href="#cb51-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate similarity and return results</span></span>
<span id="cb51-6"><a href="#cb51-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> get_similarity(text_embeddings, input_text_emb, device)</span></code></pre></div>
</div>
<div id="pmI8uPzTnOEy" class="cell code" data-execution_count="21"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="pmI8uPzTnOEy" data-outputId="fdbb70ee-9199-4d1b-91c7-a61140e76fbe">
<div class="sourceCode" id="cb52"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb52-1"><a href="#cb52-1" aria-hidden="true" tabindex="-1"></a>input_text <span class="op">=</span> <span class="st">&quot;is DALL-E2 uses a clip model inside?&quot;</span></span>
<span id="cb52-2"><a href="#cb52-2" aria-hidden="true" tabindex="-1"></a>text_embedding_similarity(input_text, text_embeddings, text_emb_model)</span></code></pre></div>
<div class="output stream stderr">
<pre><code>/usr/local/lib/python3.10/dist-packages/torch/utils/_device.py:77: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3614.)
  return func(*args, **kwargs)
</code></pre>
</div>
<div class="output execute_result" data-execution_count="21">
<pre><code>array([0.18537425, 0.2028819 , 0.21293399, 0.20692343, 0.2686563 ,
       0.31146652, 0.01873749, 0.21311942, 0.20081617, 0.25198764,
       0.26972085, 0.2460359 , 0.25822914, 0.25395477, 0.23482761,
       0.23657551, 0.17059213, 0.15917057, 0.15459308, 0.14453974,
       0.11232637, 0.18208511, 0.12710598, 0.37942073, 0.05238128,
       0.3243861 , 0.30019337, 0.06964829, 0.10325826, 0.13214464,
       0.02927516, 0.15812725, 0.10174508, 0.26262778, 0.15325922,
       0.00922206, 0.31082875, 0.04998646, 0.12929472], dtype=float32)</code></pre>
</div>
</div>
<div id="YOH0JjIUt6gu" class="cell markdown" id="YOH0JjIUt6gu">
<p><font color='77CC99'> Now, write a function that finds "Summaries" of
the k most similar ground truth texts to the user's input. function
"text_retrival"</font></p>
</div>
<div id="UzXXtOLyt3ep" class="cell code" data-execution_count="22"
id="UzXXtOLyt3ep">
<div class="sourceCode" id="cb55"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> heapq</span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-3"><a href="#cb55-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> text_retrival(k, input_text, text_embeddings, text_elements, summarized_text_elements, text_emb_model):</span>
<span id="cb55-4"><a href="#cb55-4" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate similarity scores for each text element</span></span>
<span id="cb55-5"><a href="#cb55-5" aria-hidden="true" tabindex="-1"></a>    similarities <span class="op">=</span> text_embedding_similarity(input_text, text_embeddings, text_emb_model)</span>
<span id="cb55-6"><a href="#cb55-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-7"><a href="#cb55-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve the indices of the top k most similar elements</span></span>
<span id="cb55-8"><a href="#cb55-8" aria-hidden="true" tabindex="-1"></a>    top_k_indices <span class="op">=</span> heapq.nlargest(k, <span class="bu">range</span>(<span class="bu">len</span>(similarities)), similarities.take)</span>
<span id="cb55-9"><a href="#cb55-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-10"><a href="#cb55-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select the corresponding text elements, preferring summarized text if available</span></span>
<span id="cb55-11"><a href="#cb55-11" aria-hidden="true" tabindex="-1"></a>    selected_text_elements <span class="op">=</span> [summarized_text_elements[i] <span class="cf">if</span> summarized_text_elements <span class="cf">else</span> text_elements[i] <span class="cf">for</span> i <span class="kw">in</span> top_k_indices]</span>
<span id="cb55-12"><a href="#cb55-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb55-13"><a href="#cb55-13" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">&quot;selected_text_elements&quot;</span>: selected_text_elements}</span></code></pre></div>
</div>
<div id="Arn28x_hypVi" class="cell markdown" id="Arn28x_hypVi">
<h3 id="step-122-load-the-core-llm-and-combine-them-all">Step 1.2.2:
Load the core LLM and Combine them all</h3>
</div>
<div id="zJPD8Y91yxs5" class="cell markdown" id="zJPD8Y91yxs5">
<p>We use a Question-answering model as the core of our system. In fact,
having the input text and finding the closest ground truth fact to the
input text, we can give them both to an LLM to answer the question.</p>
<p>Here we load the core LLM for our Unimodal Semi-Structured RAG. <a
href="https://huggingface.co/samwit/koala-7b">Model in HF</a></p>
</div>
<div id="fl_XCHonXtr-" class="cell code" data-execution_count="23"
id="fl_XCHonXtr-">
<div class="sourceCode" id="cb56"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb56-1"><a href="#cb56-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gc</span>
<span id="cb56-2"><a href="#cb56-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb56-3"><a href="#cb56-3" aria-hidden="true" tabindex="-1"></a><span class="co"># clean-up the memory and gpu cache</span></span>
<span id="cb56-4"><a href="#cb56-4" aria-hidden="true" tabindex="-1"></a>gc.collect()</span>
<span id="cb56-5"><a href="#cb56-5" aria-hidden="true" tabindex="-1"></a><span class="cf">if</span> torch.cuda.is_available():</span>
<span id="cb56-6"><a href="#cb56-6" aria-hidden="true" tabindex="-1"></a>  torch.cuda.empty_cache()</span></code></pre></div>
</div>
<div id="h5S1lINLzliK" class="cell code" data-execution_count="24"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:759,&quot;referenced_widgets&quot;:[&quot;610cdfc1fd524c4f924b93bed1a5c93c&quot;,&quot;3cb645725e6948c899e74f5ff41a59d9&quot;,&quot;3b178132ae874374879adcee3cb133a2&quot;,&quot;b7a8ea200ba1448dae7cb7c202670cd1&quot;,&quot;ee9e5d0e860f4268b17be40b78a77427&quot;,&quot;8ddf7e14a3994244984e9f10afa017af&quot;,&quot;62a127d4e2e84be6a65e2be4f1cfdb2d&quot;,&quot;36778d8a787f47a0b23d9f80cf48dd34&quot;,&quot;ce2c399a6d8b43c780d79bd83d83df1d&quot;,&quot;e596208a911840b69a0b600aa7371c74&quot;,&quot;c4a734bae1f04eb6a04542221dfb5467&quot;,&quot;4c277aaeb2f244459906d7669de7fc6f&quot;,&quot;fe471dec1c8b4941b8feb74eb16980f0&quot;,&quot;96a06d021fe04938adf40f0d74a82953&quot;,&quot;f6e4143a41e4414b9a9d75f4a66c80dd&quot;,&quot;2daffbaf1e7349b485aefcd46987aa51&quot;,&quot;dc634e06dc45427e8f2459544fd98f34&quot;,&quot;a7ffb9d67025403585b8476ba325bd96&quot;,&quot;9789fd7e931b43ae9f4c803f213a3c75&quot;,&quot;d02ee1bb68534c3cbb6d64a45c05d1d6&quot;,&quot;ea0a381a714d4b1b85397a13448c6082&quot;,&quot;a7e0047d86c04009b5028c6ffdd7a36a&quot;,&quot;5b104252e5704724b39e7f158a130ffa&quot;,&quot;c0ecd07094c54ceaa17a10747e7d0e48&quot;,&quot;7bd3c88b5ffe400886855d60397ecd42&quot;,&quot;0d5ea0d4090c47e18b9354ad7cfa5eb0&quot;,&quot;bed9b6896dc342bdac13187d9431bb33&quot;,&quot;682da66ff7ff466d88d935d45eb8b065&quot;,&quot;d0e5f37482664d3485e2648a07452d80&quot;,&quot;707c9aeb71c641a6ba1a9dadb0bd7bb4&quot;,&quot;56d9d98d9e824df5983f194513f21a0b&quot;,&quot;8289777f9c414f7dba9d0532c83c261a&quot;,&quot;9e3b3fb1e6c24b029f51809bdc206109&quot;,&quot;e7da1e6588e34834bce3c1ec0b0a222e&quot;,&quot;f26a3a98f0184c65935c163d1c66c5fd&quot;,&quot;27b60ee19d4044b78851fa02935073da&quot;,&quot;469f63daaa4041ec94741b75ef9c04fb&quot;,&quot;0bf88758e0384238bf68ba6c71ef6806&quot;,&quot;2aaa93395e534c0cb4031d1b001c9155&quot;,&quot;22ec1eeddb184073a235909df58bc9c5&quot;,&quot;fc38dedb5de34fcc98857232624840e0&quot;,&quot;8ca4f75f7d4d4c279e4af98bf5a418d2&quot;,&quot;d9d1fa5266894b0bb9ce74928a02d5aa&quot;,&quot;15523ab65298427cadebe6ea56246160&quot;,&quot;e903300171d145d0a925a9b14af3a58f&quot;,&quot;f9a17a3476324066b5fa1ba4bdc28d9f&quot;,&quot;06cfd388c66147968ca96c7bf50597d6&quot;,&quot;041041c363b444b3badc143b950b4ead&quot;,&quot;1a0cbbb968f045f6aea34106a3a031eb&quot;,&quot;80aa2399e22a489aa40c44e2db80090b&quot;,&quot;6139d4e81486406dafe9d05bbfa9125d&quot;,&quot;f85947bee3114e9987a9d721aef66470&quot;,&quot;99f06463ffa345faa1e83882ecaa6686&quot;,&quot;c1052bc53ffc47bfbbf7154e5d3f96e4&quot;,&quot;371de039e2214b4abfa24a1da195fb0b&quot;,&quot;559862771ca2445ba302c9c55eba423d&quot;,&quot;0277119125144be8a221f98e9947d57f&quot;,&quot;21780f10bceb46a790e2b6f66681a24b&quot;,&quot;9cdadc2009fe4c2891ab824e3235cec5&quot;,&quot;c5df2ae6c37f4edab0d814d657399658&quot;,&quot;d0da40d8833e44209f3ed731b1b22f1c&quot;,&quot;2cdd6019e32c49f0bef74d20f67030be&quot;,&quot;a4b4ebf648e34d688d418a6f868d565a&quot;,&quot;5b2920a9e966460f85054855c0e39427&quot;,&quot;9edd3ccbc4f04949b13d7a780b146d8f&quot;,&quot;2ecdfba808194a5fa9c7e2d954a7984b&quot;,&quot;6da50d6875844937b71f377f809adab4&quot;,&quot;c06b25625a504059b22c033a896c4af1&quot;,&quot;d25ddbeccc95477794f15974582a84ee&quot;,&quot;409fcfe1793f4e01b31cd4c782743f79&quot;,&quot;470c7a9e4d2a42b2935f01b5379f17b6&quot;,&quot;94d1b39f78324ee99b973aefa7a10b39&quot;,&quot;774378a8246d4bb289ad09f9f99187e6&quot;,&quot;5e7ce58da656419ea31256a30b80fa9a&quot;,&quot;ceb64b93b37c4ceb80e9edd89709c228&quot;,&quot;b08487c735674c44ba88d0e8dd7fcf07&quot;,&quot;fdee3225c35449a29987b8a863ef71aa&quot;,&quot;9b4d0e8c883f4cc7b4dcc64f93800092&quot;,&quot;edd0a4031dca4d3d965b7b49f2b6d251&quot;,&quot;371c63b560774d1c90cd4f933b932113&quot;,&quot;0321a3a2165d48bda1613ea9be2f06f5&quot;,&quot;947fc8deeca044afba10abfaf9a2e97a&quot;,&quot;1f304022b1dc4e339cc9bcb5f9f5cc0b&quot;,&quot;c3112dea8e644b3984945619b2799663&quot;,&quot;8dce4b2220bb4308a4ebfac8e806f940&quot;,&quot;0c47b559870b45e38b37243ea5d0c0de&quot;,&quot;79ffe14a32ad435a87e9224bbcc1ac88&quot;,&quot;f951b4527f734816bf8709f8bdca00d9&quot;,&quot;acc6d0f975744c368526734fed57cf51&quot;,&quot;3b43f59cc3774355a4fff8180273464b&quot;,&quot;4768eef64b404f86bfa481a1c1515155&quot;,&quot;3a8ae476c8e4452083ecca32f5e533e6&quot;,&quot;796bb6930f20427aa60f5968d5cf8e55&quot;,&quot;e61aa3a2aee048f4902ab919c712945b&quot;,&quot;fdaa5732e7d642b48fe6cad7b61dbc84&quot;,&quot;def94448f801452ea62288f2fb3f5186&quot;,&quot;810c279db6c64d33956ca95f3170ab4d&quot;,&quot;891661d502494522a45054b9634d070d&quot;,&quot;38c62672c29046e7914726c7da664e04&quot;,&quot;026ae405ecd646fb8ffa93d59fe61cdf&quot;,&quot;f9c39751799f4e2d8c9d11d9aa15025a&quot;,&quot;89f3b89739214c5d97d4b496d87ab035&quot;,&quot;5606a8fd6ed84a1e95e13afe1823a63c&quot;,&quot;85016808453949fca70967d6d17a7bd4&quot;,&quot;84ca2e4b0cff4c329624f475ae3c8683&quot;,&quot;45bce33b60474dd09a6a3c60055341f2&quot;,&quot;b8cb8eab20f74a36960aeafe8ba5c0ed&quot;,&quot;479fdcacef314dcc81a57992b2b01235&quot;,&quot;df1ecc4078eb4e78b374e24a6e551f9d&quot;,&quot;48019f72de134463bf7ea7dd5f613018&quot;,&quot;85ab5f4d5f97446a81320966a30f2b29&quot;,&quot;55ebfdd65f604169829afa80de324cf1&quot;,&quot;40b1bf262a63461da206bbd4953e4aaa&quot;,&quot;f2f9d1c85eef416690ee97945123afda&quot;,&quot;645883a5da834cef8d244fa7df2271ce&quot;,&quot;5065c13ae7164d8cb79b794d7cfe6e92&quot;,&quot;90611e38ef08499a9c2e35b1c4e0960c&quot;,&quot;f24434189ecb466db7a405495ec042c2&quot;,&quot;14cd4c56029748f6802f7b2d502fdcee&quot;,&quot;3e8fe6fb93b24f8991fb686f835e4457&quot;,&quot;58dfcd5959914a2e98dc3b57c9dbd0c0&quot;,&quot;9f00f1e98f92401b8a347fd6ad34d2cc&quot;,&quot;5738f36e1f0a4ee38f62c37109204265&quot;,&quot;c7f03581538f43aea35eb64fc2820a4a&quot;,&quot;fbe288f68dd44f1ab90649771d0ff9b2&quot;,&quot;29bfa84148e84e9f8ef88222251e07eb&quot;,&quot;a905d88ec1b44a51849e8ac3c1df3624&quot;,&quot;8e27688c5e2a418baf0013dbfbb9b4ed&quot;,&quot;2c33b77bdf054f9b9e8cff3fe09da95f&quot;,&quot;7710ea3a16ed4bcfa80c4ef7087bec71&quot;,&quot;ed19b4fc8630401db53fb1f8e3cdef59&quot;,&quot;063d22cecc164cf08e6892fcf5b56805&quot;,&quot;c56d76bae1d7424d80975e650e3653e1&quot;,&quot;ba221393e3144b65964f0b96bf8f7613&quot;,&quot;b87098e995534e38a38127d9db9f76e4&quot;,&quot;e99ae2552d4949e6994e3a7a5c88409a&quot;,&quot;5d2dd3e460154cbe980238a804f7a5b0&quot;,&quot;f5864491e9494a9cbccd2fca5ae5f31c&quot;,&quot;416f7b60ed8d46c7a8d0c16d9e8e3409&quot;,&quot;aee67d5aa162477e94373670bfff83de&quot;,&quot;0474c0c9533e47248b2e0a424f5ce2e9&quot;,&quot;d7b41b31fecc4d3c8d12a29131129565&quot;,&quot;1dd1b46f92e24a488b45c6f012e8ed1f&quot;,&quot;0ac29e64a37b467eb98ac5ff0e2517ae&quot;,&quot;fe8487f71764442896d47f8d1a36fae9&quot;,&quot;c2da1808d395416ea0b3baf48376aad2&quot;,&quot;651b0a02fdb8434e8369c7c79e293134&quot;,&quot;12701f3c22ca4846a49d0f44596d7a3c&quot;,&quot;8fcdeaf6855944f8ae38d24fd0962e94&quot;,&quot;b35198f6e36546df995b4bd59683ff22&quot;,&quot;de92507128014fa290c00368c7abf158&quot;,&quot;15c7569b07d14e5da91b85d3ff2fb56e&quot;,&quot;8115ae09a35a45c9b04a3034dabfc8b8&quot;,&quot;04c7ae4934d24c9b857d9a8dd95a32db&quot;,&quot;15904df470bf4147994166720e95f104&quot;,&quot;2deb457a34594a41803d255cadf33bc3&quot;,&quot;1695de6775544aafa19773be82999151&quot;,&quot;3b374fd046e14b068ad3c4423dd4dd36&quot;,&quot;4308f041db77446e8bc105f17639d29e&quot;,&quot;0610404b1e084d9b93652d7cb69944fc&quot;,&quot;fda29014c66a488494237389965afbe3&quot;,&quot;58506b7446b04fefa57850f68e40f46c&quot;,&quot;4fe232ac45b84817b0c77cc54187c096&quot;,&quot;069004de1b94415f99e8f869f201b2f4&quot;,&quot;a7abaf0a961a449da50820f8a928d4d6&quot;,&quot;a3a3c1dd1c0d421abc06bcff26a22b12&quot;,&quot;f848595a31cd460799272bf6ed2d2139&quot;,&quot;f47bf29e63c147ad827994e21d2019a2&quot;,&quot;e326aa5228694ad6bcf2ccba6769fb79&quot;,&quot;283a54556b4d49fc93ad0fff11061aa5&quot;,&quot;7ba5f45dcffd492ba4da81413e158581&quot;,&quot;4371dff840944cadace7e9aadd420bc0&quot;,&quot;8aceb3a5687a4881987d67f89c5db2ad&quot;,&quot;a1011469c6a64a7eb14f6afc93ff394c&quot;,&quot;fc191fd26fc8464496fcb11ba83833f0&quot;,&quot;e75251863c16456f80f8f7d7dde69e0f&quot;,&quot;696b2b209f3d48b2882d31846a9cd7e9&quot;,&quot;7b8215271b3f4fa98ef8c64b48244eae&quot;,&quot;6da5fdc12c1048eb9c42705edc6afbfc&quot;,&quot;87217f85d5244c5a9a0fa61ffe6b81ba&quot;,&quot;27735975b2914200b459883cef309712&quot;,&quot;23209f4a09324d7c8ac23db7b88e7060&quot;,&quot;735ef4ec531b48ba98ad89fd093a7e9e&quot;,&quot;cd04a0ba015b4baeba9595c151c2993d&quot;,&quot;c6d27cc8011f401c8325f8709f33e6cb&quot;,&quot;839af441cb6e4acf8a6646fb9c80c5d7&quot;,&quot;72dc2ada9666418cb29d2fe5db734ad8&quot;,&quot;268550f971a348b7ac6eaacd819d30d5&quot;,&quot;b6b00828f75440d895eadebe50e72e21&quot;,&quot;332c663ba0284e0899a94ec75109186b&quot;,&quot;2bd1eca97dd94712a1eddd276620e69a&quot;,&quot;77699b2bae5f4ba68b2b17c2c3b65fc5&quot;,&quot;0d3fecc8088b4660b77b7bb2f7546c3b&quot;,&quot;7c19bbcd61134843877cf1e0b0769bec&quot;,&quot;a271f3c08a1d4df796465cbf7eaed348&quot;,&quot;ed2e7ba463c34d849ded073e5f2d2e96&quot;,&quot;e4a96c2367ac40fbbc1c0a573c4151b8&quot;,&quot;2df077fca6d2458f9307c08785ff809b&quot;,&quot;5d80a45c09474f1cb670bade1bec6838&quot;,&quot;d98da366edd84b5983d480b1f315c478&quot;,&quot;b0a5217ff5534709baed65c27e167208&quot;,&quot;01dd377d3ab44acbbd65c90111096ec2&quot;,&quot;a322145c562a4536994ab2d909af593f&quot;,&quot;386def88f0e54535a75c0d0a4d4beea7&quot;,&quot;3cfbc66d88864ffd81c45a1e462679b9&quot;,&quot;1fb8293d517a4bf680984fe9bee96d04&quot;,&quot;00404148a59247a2b70210db286fc84f&quot;,&quot;66da01da8ad0428f81d1c0c4cfc9a689&quot;,&quot;1b673e15ff5640f5b49dc96cbd7a16d3&quot;,&quot;1fb43fa4343040c98d71b5dec6c45568&quot;,&quot;c2e3afed77754d7c87916b9a09e36cc2&quot;,&quot;2674ba7897c849269e4dac80abea9427&quot;,&quot;ba559aa3070e481198e796e971247e99&quot;,&quot;900fd34b88ef43f9b99d8d00e8f39c2a&quot;,&quot;fed4cfc9b3cb4bd799f9213ffc43fd7b&quot;,&quot;54516274adbf4bfc880a227e5587b237&quot;,&quot;6635ace9ac034693bbc992bb6d1d6af4&quot;,&quot;b2dabca2336f489dba5073e8ccebe8e0&quot;,&quot;32fdafdf7fcd4b44a0811af145318b18&quot;,&quot;a189972b1c42498887221ab7f1a22b3a&quot;,&quot;24f9eb66857449e6b25a024d93b97410&quot;,&quot;aa723ea07d3e46d0afa4dd2b6b0f0d14&quot;,&quot;07bb55cfce0f4f89a22dceefbe6810e4&quot;,&quot;7467f99aba87476bbda2b886e6f6bbdd&quot;,&quot;ac30b3ceb8984ec7b46eda83d54afdce&quot;,&quot;088467ed027c4655b7061e7ce110de72&quot;,&quot;155318870ecf4bd38e70ab3f99ff7ff5&quot;,&quot;c0403c15a3dd4504bd6db5bcd3af59a4&quot;,&quot;9a601a25743948bfb3bc0254a8229b98&quot;,&quot;f324303a6f6d47b59999bc8d724d3f58&quot;,&quot;2b11cdcb37064c328f5758a7d8f81116&quot;,&quot;a08641edeb3943cd9bdd4e680fbe16cd&quot;,&quot;00363aa2f51e4becad798830c493d911&quot;,&quot;dccd84e5d5c8436c99d84570bb1eb207&quot;,&quot;74392672079544ae924d2d776960df62&quot;,&quot;8786fa80972d4012bf545a1041495ba2&quot;,&quot;bd503a59f1fc4bce93f393eb34e11e6b&quot;,&quot;b94d3bb956d546f48cd60331cc0c2614&quot;,&quot;7b108c6faa8f4f2b96b94facd4b23883&quot;,&quot;ea9260850c3f447eb1c0cfb631a3f808&quot;,&quot;370c2ba8b63445ad80015655d934b0a4&quot;,&quot;8b22edaec2fa4f5c8437b7c1e77b18be&quot;]}"
id="h5S1lINLzliK" data-outputId="7f03c1e5-e031-4b56-a583-3d1435ba4b9b">
<div class="sourceCode" id="cb57"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> LlamaTokenizer, LlamaForCausalLM, GenerationConfig, pipeline</span>
<span id="cb57-2"><a href="#cb57-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb57-3"><a href="#cb57-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> textwrap</span>
<span id="cb57-4"><a href="#cb57-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-5"><a href="#cb57-5" aria-hidden="true" tabindex="-1"></a>model <span class="op">=</span> LlamaForCausalLM.from_pretrained(</span>
<span id="cb57-6"><a href="#cb57-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;samwit/koala-7b&quot;</span>,</span>
<span id="cb57-7"><a href="#cb57-7" aria-hidden="true" tabindex="-1"></a>    load_in_8bit<span class="op">=</span><span class="va">True</span>,</span>
<span id="cb57-8"><a href="#cb57-8" aria-hidden="true" tabindex="-1"></a>    device_map<span class="op">=</span><span class="st">&#39;auto&#39;</span>,</span>
<span id="cb57-9"><a href="#cb57-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb57-10"><a href="#cb57-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb57-11"><a href="#cb57-11" aria-hidden="true" tabindex="-1"></a>tokenizer <span class="op">=</span> LlamaTokenizer.from_pretrained(<span class="st">&quot;samwit/koala-7b&quot;</span>)</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb58"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb58-1"><a href="#cb58-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;610cdfc1fd524c4f924b93bed1a5c93c&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb59"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;4c277aaeb2f244459906d7669de7fc6f&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb60"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb60-1"><a href="#cb60-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5b104252e5704724b39e7f158a130ffa&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb61"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;e7da1e6588e34834bce3c1ec0b0a222e&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb62"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb62-1"><a href="#cb62-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;e903300171d145d0a925a9b14af3a58f&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb63"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;559862771ca2445ba302c9c55eba423d&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb64"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb64-1"><a href="#cb64-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;6da50d6875844937b71f377f809adab4&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb65"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;9b4d0e8c883f4cc7b4dcc64f93800092&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb66"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb66-1"><a href="#cb66-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;acc6d0f975744c368526734fed57cf51&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb67"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;026ae405ecd646fb8ffa93d59fe61cdf&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb68"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb68-1"><a href="#cb68-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;85ab5f4d5f97446a81320966a30f2b29&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb69"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;9f00f1e98f92401b8a347fd6ad34d2cc&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb70"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb70-1"><a href="#cb70-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;c56d76bae1d7424d80975e650e3653e1&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb71"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;0ac29e64a37b467eb98ac5ff0e2517ae&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb72"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb72-1"><a href="#cb72-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;15904df470bf4147994166720e95f104&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb73"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;a3a3c1dd1c0d421abc06bcff26a22b12&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb74"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb74-1"><a href="#cb74-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;696b2b209f3d48b2882d31846a9cd7e9&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb75"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;268550f971a348b7ac6eaacd819d30d5&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb76"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb76-1"><a href="#cb76-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5d80a45c09474f1cb670bade1bec6838&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb77"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;1fb43fa4343040c98d71b5dec6c45568&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb78"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;24f9eb66857449e6b25a024d93b97410&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb79"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb79-1"><a href="#cb79-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;a08641edeb3943cd9bdd4e680fbe16cd&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output stream stderr">
<pre><code>You are using the default legacy behaviour of the &lt;class &#39;transformers.models.llama.tokenization_llama.LlamaTokenizer&#39;&gt;. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
</code></pre>
</div>
</div>
<div id="gPLjb1gmAqkH" class="cell code" data-execution_count="25"
id="gPLjb1gmAqkH">
<div class="sourceCode" id="cb81"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb81-1"><a href="#cb81-1" aria-hidden="true" tabindex="-1"></a>pipeline <span class="op">=</span> pipeline(</span>
<span id="cb81-2"><a href="#cb81-2" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;text-generation&quot;</span>,</span>
<span id="cb81-3"><a href="#cb81-3" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span>model,</span>
<span id="cb81-4"><a href="#cb81-4" aria-hidden="true" tabindex="-1"></a>    tokenizer<span class="op">=</span>tokenizer,</span>
<span id="cb81-5"><a href="#cb81-5" aria-hidden="true" tabindex="-1"></a>    max_length<span class="op">=</span><span class="dv">512</span>,</span>
<span id="cb81-6"><a href="#cb81-6" aria-hidden="true" tabindex="-1"></a>    temperature<span class="op">=</span><span class="fl">0.7</span>,</span>
<span id="cb81-7"><a href="#cb81-7" aria-hidden="true" tabindex="-1"></a>    top_p<span class="op">=</span><span class="fl">0.95</span>,</span>
<span id="cb81-8"><a href="#cb81-8" aria-hidden="true" tabindex="-1"></a>    repetition_penalty<span class="op">=</span><span class="fl">1.15</span>)</span>
<span id="cb81-9"><a href="#cb81-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb81-10"><a href="#cb81-10" aria-hidden="true" tabindex="-1"></a>tokenizer.pad_token_id <span class="op">=</span> tokenizer.eos_token_id</span></code></pre></div>
</div>
<div id="RO2fptLQ3HlW" class="cell markdown" id="RO2fptLQ3HlW">
<p>Now, what follows is our Prompt, based on that, do the task
bellow.</p>
<p><font color='77CC99'> Based on the prompt and what we have done
before, write a function that answers the user's question by finding the
most related ground truth text(fact) by giving the prompt to LLM.
Function "Unimodal_Question_Answering" </font></p>
</div>
<div id="Ij8m2NMZ18DB" class="cell code" data-execution_count="26"
id="Ij8m2NMZ18DB">
<div class="sourceCode" id="cb82"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb82-1"><a href="#cb82-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prompt</span></span>
<span id="cb82-2"><a href="#cb82-2" aria-hidden="true" tabindex="-1"></a>prompt_text <span class="op">=</span> <span class="st">&quot;&quot;&quot;ANSWER the QUESTION in conformity to on FACTS. </span><span class="ch">\n</span></span>
<span id="cb82-3"><a href="#cb82-3" aria-hidden="true" tabindex="-1"></a><span class="st">FACTS: </span><span class="ch">\n</span><span class="st"> </span><span class="sc">{text_facts}</span><span class="st">. </span><span class="ch">\n</span></span>
<span id="cb82-4"><a href="#cb82-4" aria-hidden="true" tabindex="-1"></a><span class="st">QUESTION: </span><span class="sc">{user_question}</span><span class="st"> </span><span class="ch">\n</span></span>
<span id="cb82-5"><a href="#cb82-5" aria-hidden="true" tabindex="-1"></a><span class="st">ANSWER:  &quot;&quot;&quot;</span></span></code></pre></div>
</div>
<div id="cgH4EVCa3wh7" class="cell code" data-execution_count="27"
id="cgH4EVCa3wh7">
<div class="sourceCode" id="cb83"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb83-1"><a href="#cb83-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Unimodal_Question_Answering(input_text, k<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb83-2"><a href="#cb83-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve relevant text elements</span></span>
<span id="cb83-3"><a href="#cb83-3" aria-hidden="true" tabindex="-1"></a>    retrieved_elements <span class="op">=</span> text_retrival(k, input_text, text_embeddings, text_elements, summarized_text_elements, text_emb_model)</span>
<span id="cb83-4"><a href="#cb83-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-5"><a href="#cb83-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select the best response (assuming the first one is the best)</span></span>
<span id="cb83-6"><a href="#cb83-6" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> retrieved_elements[<span class="st">&quot;selected_text_elements&quot;</span>][<span class="dv">0</span>]</span>
<span id="cb83-7"><a href="#cb83-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb83-8"><a href="#cb83-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> response</span></code></pre></div>
</div>
<div id="6ygX1HvaFrqq" class="cell code" data-execution_count="28"
id="6ygX1HvaFrqq">
<div class="sourceCode" id="cb84"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb84-1"><a href="#cb84-1" aria-hidden="true" tabindex="-1"></a>input_text <span class="op">=</span> <span class="st">&quot;is DALL-E2 uses a clip model inside?&quot;</span></span>
<span id="cb84-2"><a href="#cb84-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb84-3"><a href="#cb84-3" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> Unimodal_Question_Answering(input_text,k<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div id="BUfBQBc1X0Ie" class="cell code" data-execution_count="29"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="BUfBQBc1X0Ie" data-outputId="350be857-c85e-4604-a8a2-d22685bd1049">
<div class="sourceCode" id="cb85"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb85-1"><a href="#cb85-1" aria-hidden="true" tabindex="-1"></a>response</span></code></pre></div>
<div class="output execute_result" data-execution_count="29">
<pre><code>{&#39;summary_text&#39;: &#39;Since its release, CLIP has been used extensively to steer generative image models towards text prompts. Nichol et al. [35] showed classiﬁer-free guidance works more favorably than CLIP guidance for text conditional image generation. Zhou and Crowson [9] trained diffusion models conditioned on CLIP text embeddings, allowing for direct text-conditional imagegeneration.&#39;}</code></pre>
</div>
</div>
<div id="Ow9VAnRjSc6Y" class="cell markdown" id="Ow9VAnRjSc6Y">
<h1 id="2---multimodal-rag">2 - Multimodal RAG</h1>
</div>
<div id="tf0B7mSrUDwg" class="cell markdown" id="tf0B7mSrUDwg">
<p>In this section, we want to add another modality to our unimodal RAG.
What happens if we can consider images as ground truth facts?</p>
<p>We have stored all ground truth images. Thus, in this step, we should
extract image embeddings for comparison with textual input
embeddings</p>
</div>
<div id="0aa7f52f-bf5c-4ba4-af72-b2ccba59a4cf" class="cell markdown"
id="0aa7f52f-bf5c-4ba4-af72-b2ccba59a4cf">
<h2 id="21---loading-clip-model-for-extracting-embeddings">2.1 - Loading
CLIP Model for Extracting Embeddings</h2>
</div>
<div id="J9beLY0n6aq8" class="cell markdown" id="J9beLY0n6aq8">
<p><font color='77CC99'> Load CLIP model for extracting textual and
visial embeddings, then convert all input images to their corresponding
vectors.</p>
<p><a
href="https://huggingface.co/docs/transformers/model_doc/clip">Huggingface
Link</a> </font></p>
</div>
<div id="kOSEU_Tryj4Z" class="cell code" data-execution_count="30"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:273,&quot;referenced_widgets&quot;:[&quot;146dfc7f5e21495f978b7948aa12905f&quot;,&quot;172919d7d5ea4cd1bb425f28ffe707e9&quot;,&quot;731f330af8124e8f8ab9cc9601b8a3b5&quot;,&quot;66586548bd0c4f9a862bdc2fc575cc20&quot;,&quot;9152c707264c4f13a20b3c86ba2e7743&quot;,&quot;e282b37437fd46b4a2abc781f1451d68&quot;,&quot;fee0906b2b04474eb5cdcddb21c543a1&quot;,&quot;88eb038331d04e0f83476730a6413f4e&quot;,&quot;3f7d89b5d2f44a73b219b86d9c88ed4b&quot;,&quot;b5ab16f7ab4b497dbbd4b17a3d258c41&quot;,&quot;4716a412ae3c46b09c7fb34ffc89956f&quot;,&quot;a97e9bb5dcd84869b8fdd503aa59c050&quot;,&quot;48f54c24c0d145238aa71f94755d5dc0&quot;,&quot;1b65bd006ced44029a4c103402604754&quot;,&quot;4b6673240bd14f84821c93f5e73011a2&quot;,&quot;0628acd50aff49a2b04c309a8725a385&quot;,&quot;e97dcaa6b25d41a58cd5025a3b552ec0&quot;,&quot;f05a42ae097e4049b08aa05ee6d6ce8a&quot;,&quot;64a0b809f7d24207b69820deaf94be04&quot;,&quot;b60b6573a7474f66aaf2046e9140a681&quot;,&quot;d3c3b25eec8241e2bc49670135924d74&quot;,&quot;bd964293f02544c7a7b8ac76a78f431b&quot;,&quot;2f6863aeb5c5453884b3cac6b49f8915&quot;,&quot;74e63f5e047e4c0ebb90738ed6e627e4&quot;,&quot;c350eb46e2634bc0b336a7c82c58da5a&quot;,&quot;81535c6d23e84636bbe0d95831c70813&quot;,&quot;1d86b5b877ea4de4a3d8546c8fc1fafe&quot;,&quot;9a5e481ebe7b47a997d5bf015e2af147&quot;,&quot;11b42f238c0c45fbaf3a6e577eaf436f&quot;,&quot;a7d07d18923940c4965b451619d3b714&quot;,&quot;96bdf3e602614df1ad2ea749d0e6a86c&quot;,&quot;e133847cbe204833b4ed92c0a76190dc&quot;,&quot;61fd692b17d246b0ae05df8745da5444&quot;,&quot;5dbd9de8d9284200b90cb5fc65d6ac1b&quot;,&quot;82a726dcb2e14ea6bef32604a188537a&quot;,&quot;6759071271ed45aa8b145db0c3b8b287&quot;,&quot;8df0a52ad30840cab927426ba342c2a1&quot;,&quot;394c5e9287cd4b58beb711d8998dc68d&quot;,&quot;53e205aafebb4a579f031fa3a288fe2a&quot;,&quot;1cc5f2890cac46ac81d45863baa32839&quot;,&quot;c2b8aba1d79146eea78fa30338cf00bb&quot;,&quot;60f1714198ef4bd2968494cd639db96d&quot;,&quot;3999a889dd7e4bce945b9bd473a6cb9a&quot;,&quot;0db646b22986401ea2386e482a6a2992&quot;,&quot;a536aba068094b4a96ee93f2138fbe3b&quot;,&quot;8100a21ffccb49b59444fe87ef924f38&quot;,&quot;17ef867908bf4cd9b6b2c200dff52969&quot;,&quot;f0779e7f92754982aa919835be896a4c&quot;,&quot;2f2f03dd7a434359942dce379f682e01&quot;,&quot;0d61a645b485482298112d2fdccc17f7&quot;,&quot;8fad17e4bdee49d6a04f2cab7bb2cf9e&quot;,&quot;fb1959b0077c488d997d7ebf6ab8f4ba&quot;,&quot;fcfb9a23b04c4eef9b34e9c1e043b3be&quot;,&quot;1d4519e6c89546e5803ef33f95562e97&quot;,&quot;dbd360e7e95844518562fa520d9428f6&quot;,&quot;8f242f92115e48b993f5731ad19e39ab&quot;,&quot;6e7deac4c3e34d88a860e1da247dfbb5&quot;,&quot;2c769df8d3ac473392e76eb7c925023f&quot;,&quot;53a7bc6ebf164b209b493cea511e2ba7&quot;,&quot;23f02eb43d03452baa7518041e449a3b&quot;,&quot;72169c9d5eca4e6cb23499f4610d2f03&quot;,&quot;51994cc253a14a78baa9aabf0039fddc&quot;,&quot;2ac8e1bfb7ce49fbaf5abe84648d352c&quot;,&quot;5d2ac1cf67e44682845fb9e2840a33f0&quot;,&quot;4906b54edd514ea297b47ac5109c4c2b&quot;,&quot;39c70eb5df4b42e6968c493e14241c90&quot;,&quot;c13328e1dfa349ac9ddde2d141ed3879&quot;,&quot;c508f58983954dff905bc729543160d1&quot;,&quot;078e216003304a378305d8ff89a4470b&quot;,&quot;401adf4099534cc4ad2ca10d375a4442&quot;,&quot;e12eee9c29604e6fa29b6d6ff695c019&quot;,&quot;deec879c67b14fd0a37ccc71102916b1&quot;,&quot;3b681c611ed1438a8ed2ebd79a287d83&quot;,&quot;f1e86cdc1f8b448f8e9d518722b51f5f&quot;,&quot;5e2c4d7754ba49228eac1e8342cb6461&quot;,&quot;d539134225d045419f13b4d902c49fad&quot;,&quot;299065eae71040549e9867d1a9e48da1&quot;,&quot;fbcd5f992617495d89ddf2a0ce00454d&quot;,&quot;e6410f18632646f49761e7e98c437709&quot;,&quot;b702a07636414588b1b44eb019615c00&quot;,&quot;2cdad595abdb48f1ac100c16e6a9eca5&quot;,&quot;9a4ac5d59f6b433ab916ea9539b4019c&quot;,&quot;d5315be0f805414fb8d9c581cff748f9&quot;,&quot;907861143953401b9b71bd76ec148bc7&quot;,&quot;81748082e90e49f8b7651ac68fd5ccdd&quot;,&quot;250059484d814d8396fd6ba2de4976f9&quot;,&quot;62e42736ad9e492398d447e9c1a3e772&quot;,&quot;96fb2b5962264acca92fa84581081161&quot;]}"
id="kOSEU_Tryj4Z" data-outputId="4d99f68e-734a-4597-821a-f646ffbd0978">
<div class="sourceCode" id="cb87"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb87-1"><a href="#cb87-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb87-2"><a href="#cb87-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> requests</span>
<span id="cb87-3"><a href="#cb87-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> CLIPModel, CLIPProcessor</span>
<span id="cb87-4"><a href="#cb87-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-5"><a href="#cb87-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Load CLIP model and processor</span></span>
<span id="cb87-6"><a href="#cb87-6" aria-hidden="true" tabindex="-1"></a>clip_model <span class="op">=</span> CLIPModel.from_pretrained(<span class="st">&quot;openai/clip-vit-base-patch32&quot;</span>).to(device)</span>
<span id="cb87-7"><a href="#cb87-7" aria-hidden="true" tabindex="-1"></a>clip_processor <span class="op">=</span> CLIPProcessor.from_pretrained(<span class="st">&quot;openai/clip-vit-base-patch32&quot;</span>)</span>
<span id="cb87-8"><a href="#cb87-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-9"><a href="#cb87-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Textual and visual models are part of the CLIPModel</span></span>
<span id="cb87-10"><a href="#cb87-10" aria-hidden="true" tabindex="-1"></a>textual_clip_model <span class="op">=</span> clip_model.text_model</span>
<span id="cb87-11"><a href="#cb87-11" aria-hidden="true" tabindex="-1"></a>visual_clip_model <span class="op">=</span> clip_model.vision_model</span>
<span id="cb87-12"><a href="#cb87-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb87-13"><a href="#cb87-13" aria-hidden="true" tabindex="-1"></a>textual_clip_tokenizer <span class="op">=</span> clip_processor.tokenizer</span></code></pre></div>
<div class="output display_data">
<div class="sourceCode" id="cb88"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb88-1"><a href="#cb88-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;146dfc7f5e21495f978b7948aa12905f&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb89"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb89-1"><a href="#cb89-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;a97e9bb5dcd84869b8fdd503aa59c050&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb90"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb90-1"><a href="#cb90-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;2f6863aeb5c5453884b3cac6b49f8915&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb91"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb91-1"><a href="#cb91-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;5dbd9de8d9284200b90cb5fc65d6ac1b&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb92"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb92-1"><a href="#cb92-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;a536aba068094b4a96ee93f2138fbe3b&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb93"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb93-1"><a href="#cb93-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;8f242f92115e48b993f5731ad19e39ab&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb94"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb94-1"><a href="#cb94-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;c13328e1dfa349ac9ddde2d141ed3879&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
<div class="output display_data">
<div class="sourceCode" id="cb95"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb95-1"><a href="#cb95-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;model_id&quot;</span><span class="fu">:</span><span class="st">&quot;fbcd5f992617495d89ddf2a0ce00454d&quot;</span><span class="fu">,</span><span class="dt">&quot;version_major&quot;</span><span class="fu">:</span><span class="dv">2</span><span class="fu">,</span><span class="dt">&quot;version_minor&quot;</span><span class="fu">:</span><span class="dv">0</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div id="v0Ckb62n7sK7" class="cell code" data-execution_count="40"
id="v0Ckb62n7sK7">
<div class="sourceCode" id="cb96"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb96-1"><a href="#cb96-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> torch</span>
<span id="cb96-2"><a href="#cb96-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> PIL <span class="im">import</span> Image</span>
<span id="cb96-3"><a href="#cb96-3" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> gc</span>
<span id="cb96-4"><a href="#cb96-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> glob</span>
<span id="cb96-5"><a href="#cb96-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-6"><a href="#cb96-6" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_images(image_paths, clip_processor, visual_clip_model):</span>
<span id="cb96-7"><a href="#cb96-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-8"><a href="#cb96-8" aria-hidden="true" tabindex="-1"></a>    <span class="co"># List to store all embeddings</span></span>
<span id="cb96-9"><a href="#cb96-9" aria-hidden="true" tabindex="-1"></a>    all_embeddings <span class="op">=</span> []</span>
<span id="cb96-10"><a href="#cb96-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-11"><a href="#cb96-11" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> image_path <span class="kw">in</span> image_paths:</span>
<span id="cb96-12"><a href="#cb96-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-13"><a href="#cb96-13" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Open image</span></span>
<span id="cb96-14"><a href="#cb96-14" aria-hidden="true" tabindex="-1"></a>        image <span class="op">=</span> Image.<span class="bu">open</span>(image_path)</span>
<span id="cb96-15"><a href="#cb96-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-16"><a href="#cb96-16" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Create inputs</span></span>
<span id="cb96-17"><a href="#cb96-17" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> clip_processor(images<span class="op">=</span>image, return_tensors<span class="op">=</span><span class="st">&quot;pt&quot;</span>, padding<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb96-18"><a href="#cb96-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-19"><a href="#cb96-19" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Get image embedding</span></span>
<span id="cb96-20"><a href="#cb96-20" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb96-21"><a href="#cb96-21" aria-hidden="true" tabindex="-1"></a>            image_embedding <span class="op">=</span> visual_clip_model(<span class="op">**</span>inputs).pooler_output</span>
<span id="cb96-22"><a href="#cb96-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-23"><a href="#cb96-23" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Append to list</span></span>
<span id="cb96-24"><a href="#cb96-24" aria-hidden="true" tabindex="-1"></a>        all_embeddings.append(image_embedding)</span>
<span id="cb96-25"><a href="#cb96-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-26"><a href="#cb96-26" aria-hidden="true" tabindex="-1"></a>        <span class="co"># Clear cache</span></span>
<span id="cb96-27"><a href="#cb96-27" aria-hidden="true" tabindex="-1"></a>        <span class="kw">del</span> image, inputs</span>
<span id="cb96-28"><a href="#cb96-28" aria-hidden="true" tabindex="-1"></a>        gc.collect()</span>
<span id="cb96-29"><a href="#cb96-29" aria-hidden="true" tabindex="-1"></a>        torch.cuda.empty_cache()</span>
<span id="cb96-30"><a href="#cb96-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-31"><a href="#cb96-31" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Stack list of tensors</span></span>
<span id="cb96-32"><a href="#cb96-32" aria-hidden="true" tabindex="-1"></a>    all_embeddings <span class="op">=</span> torch.stack(all_embeddings)</span>
<span id="cb96-33"><a href="#cb96-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-34"><a href="#cb96-34" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> all_embeddings</span>
<span id="cb96-35"><a href="#cb96-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-36"><a href="#cb96-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb96-37"><a href="#cb96-37" aria-hidden="true" tabindex="-1"></a><span class="co"># Usage</span></span>
<span id="cb96-38"><a href="#cb96-38" aria-hidden="true" tabindex="-1"></a>images_path <span class="op">=</span> glob.glob(<span class="st">&#39;./images/*&#39;</span>)</span>
<span id="cb96-39"><a href="#cb96-39" aria-hidden="true" tabindex="-1"></a>images_embeddings <span class="op">=</span> process_images(images_path, clip_processor, visual_clip_model)</span></code></pre></div>
</div>
<div id="UBOqu26c886c" class="cell markdown" id="UBOqu26c886c">
<p>As we are using unimodsl LLM, we need to make image's information
understandable for LLM. Hence, we extract textual information of imaged
as "Caption" store them in "captions" list.</p>
<p><font color='77CC99'>Write the corresponding code.</font></p>
<p><a
href="https://huggingface.co/nlpconnect/vit-gpt2-image-captioning">Image
Captioning HF Model</a></p>
</div>
<div id="-oCOEUMoYEcB" class="cell code" data-execution_count="68"
id="-oCOEUMoYEcB">
<div class="sourceCode" id="cb97"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb97-1"><a href="#cb97-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> generate_caption_embeddings(captions_list, textual_clip_model, textual_clip_tokenizer, device):</span>
<span id="cb97-2"><a href="#cb97-2" aria-hidden="true" tabindex="-1"></a>    caption_embeddings <span class="op">=</span> []</span>
<span id="cb97-3"><a href="#cb97-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-4"><a href="#cb97-4" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> caption <span class="kw">in</span> captions_list:</span>
<span id="cb97-5"><a href="#cb97-5" aria-hidden="true" tabindex="-1"></a>        inputs <span class="op">=</span> textual_clip_tokenizer(caption[<span class="st">&#39;generated_text&#39;</span>], return_tensors<span class="op">=</span><span class="st">&quot;pt&quot;</span>, padding<span class="op">=</span><span class="va">True</span>, truncation<span class="op">=</span><span class="va">True</span>).to(device)</span>
<span id="cb97-6"><a href="#cb97-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> torch.no_grad():</span>
<span id="cb97-7"><a href="#cb97-7" aria-hidden="true" tabindex="-1"></a>            caption_embedding <span class="op">=</span> textual_clip_model(<span class="op">**</span>inputs).last_hidden_state.mean(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb97-8"><a href="#cb97-8" aria-hidden="true" tabindex="-1"></a>            caption_embeddings.append(caption_embedding.squeeze(<span class="dv">0</span>))</span>
<span id="cb97-9"><a href="#cb97-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb97-10"><a href="#cb97-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> torch.stack(caption_embeddings)</span></code></pre></div>
</div>
<div id="XNMyGvP688hB" class="cell code" data-execution_count="42"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="XNMyGvP688hB" data-outputId="c8296adc-966a-4870-a14f-6151034ec240">
<div class="sourceCode" id="cb98"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb98-1"><a href="#cb98-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb98-2"><a href="#cb98-2" aria-hidden="true" tabindex="-1"></a>image_to_text <span class="op">=</span> pipeline(<span class="st">&quot;image-to-text&quot;</span>, model<span class="op">=</span><span class="st">&quot;nlpconnect/vit-gpt2-image-captioning&quot;</span>)</span>
<span id="cb98-3"><a href="#cb98-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-4"><a href="#cb98-4" aria-hidden="true" tabindex="-1"></a><span class="co">### To Do </span><span class="al">###</span></span>
<span id="cb98-5"><a href="#cb98-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-6"><a href="#cb98-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> transformers <span class="im">import</span> pipeline</span>
<span id="cb98-7"><a href="#cb98-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-8"><a href="#cb98-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Initialize the pipeline for image-to-text conversion</span></span>
<span id="cb98-9"><a href="#cb98-9" aria-hidden="true" tabindex="-1"></a>image_to_text <span class="op">=</span> pipeline(<span class="st">&quot;image-to-text&quot;</span>, model<span class="op">=</span><span class="st">&quot;nlpconnect/vit-gpt2-image-captioning&quot;</span>, device<span class="op">=</span>device)</span>
<span id="cb98-10"><a href="#cb98-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-11"><a href="#cb98-11" aria-hidden="true" tabindex="-1"></a><span class="co"># Assuming the image_to_text pipeline and other models are correctly loaded</span></span>
<span id="cb98-12"><a href="#cb98-12" aria-hidden="true" tabindex="-1"></a>images_path <span class="op">=</span> glob.glob(<span class="st">&#39;./images/*&#39;</span>)</span>
<span id="cb98-13"><a href="#cb98-13" aria-hidden="true" tabindex="-1"></a>captions_list <span class="op">=</span> [image_to_text(Image.<span class="bu">open</span>(img_path)) <span class="cf">for</span> img_path <span class="kw">in</span> images_path]</span>
<span id="cb98-14"><a href="#cb98-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb98-15"><a href="#cb98-15" aria-hidden="true" tabindex="-1"></a><span class="co">### End </span><span class="al">###</span></span></code></pre></div>
<div class="output stream stderr">
<pre><code>Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model&#39;s feature extractor configuration.
Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model&#39;s feature extractor configuration.
</code></pre>
</div>
</div>
<div id="SXZH79t225mF" class="cell code" data-execution_count="67"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="SXZH79t225mF" data-outputId="bcfdd75a-9548-4c6f-86ad-a642237bfd52">
<div class="sourceCode" id="cb100"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb100-1"><a href="#cb100-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb100-2"><a href="#cb100-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-3"><a href="#cb100-3" aria-hidden="true" tabindex="-1"></a>captions_list <span class="op">=</span> np.array(captions_list).ravel()</span>
<span id="cb100-4"><a href="#cb100-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb100-5"><a href="#cb100-5" aria-hidden="true" tabindex="-1"></a>captions_list[:<span class="dv">12</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="67">
<pre><code>array([{&#39;generated_text&#39;: &#39;a person holding a green plant in their hand &#39;},
       {&#39;generated_text&#39;: &#39;people on skis on a snowy slope &#39;},
       {&#39;generated_text&#39;: &#39;a living room with a table and chairs &#39;},
       {&#39;generated_text&#39;: &#39;a toy elephant with a red handle and a blue and white background &#39;},
       {&#39;generated_text&#39;: &#39;a dog wearing a hat and a flag &#39;},
       {&#39;generated_text&#39;: &#39;a collage of photos of people in a street &#39;},
       {&#39;generated_text&#39;: &#39;a man with a mask on &#39;},
       {&#39;generated_text&#39;: &#39;a pair of black shoes with a white heel &#39;},
       {&#39;generated_text&#39;: &#39;a person holding a green plant in their hand &#39;},
       {&#39;generated_text&#39;: &#39;a kitchen with a refrigerator, stove, microwave and a table &#39;},
       {&#39;generated_text&#39;: &#39;a woman is riding a skateboard in a crowded street &#39;},
       {&#39;generated_text&#39;: &#39;a large building with a large clock on it &#39;}],
      dtype=object)</code></pre>
</div>
</div>
<div id="zin6clfhYG4Q" class="cell code" data-execution_count="69"
id="zin6clfhYG4Q">
<div class="sourceCode" id="cb102"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb102-1"><a href="#cb102-1" aria-hidden="true" tabindex="-1"></a>caption_embeddings <span class="op">=</span> generate_caption_embeddings(captions_list, textual_clip_model, textual_clip_tokenizer, device)</span></code></pre></div>
</div>
<div id="tE6Ecj0h6A34" class="cell code" data-execution_count="70"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;}"
id="tE6Ecj0h6A34" data-outputId="46e6e5b5-3de3-4da0-fb06-5dcb19081274">
<div class="sourceCode" id="cb103"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb103-1"><a href="#cb103-1" aria-hidden="true" tabindex="-1"></a>caption_embeddings[:<span class="dv">12</span>]</span></code></pre></div>
<div class="output execute_result" data-execution_count="70">
<pre><code>tensor([[ 0.6607, -0.7599, -0.1563,  ..., -0.2615,  0.0344, -0.1142],
        [ 0.1877, -0.0785,  0.7978,  ...,  0.4225,  0.9018,  0.0136],
        [ 0.7590,  0.2619, -0.1598,  ...,  0.5904,  0.6454,  0.0085],
        ...,
        [ 0.8570, -0.3866,  0.3679,  ...,  0.6092,  1.1859, -0.0879],
        [ 0.6250, -0.2662,  0.9190,  ...,  0.8142,  0.8735, -0.1756],
        [ 0.5792,  0.1005, -0.5525,  ...,  0.5149,  0.0015, -0.4678]],
       device=&#39;cuda:0&#39;)</code></pre>
</div>
</div>
<div id="bJCMakba-zuG" class="cell markdown" id="bJCMakba-zuG">
<p>Ok, now that we have every thing ready, we can code the Multimodal
Semi-Structured RAG</p>
</div>
<div id="ytZvBDF4-wJo" class="cell markdown" id="ytZvBDF4-wJo">
<h2 id="22---multimodal-semi-structured-rag">2.2 - Multimodal
Semi-Structured RAG</h2>
</div>
<div id="GyYOZcmQBkCn" class="cell markdown" id="GyYOZcmQBkCn">
<h3 id="step-221-most-similar-ground-truth-image-ectraction">Step 2.2.1:
Most Similar Ground Truth Image Ectraction</h3>
</div>
<div id="Oh1fWz_3BsHb" class="cell markdown" id="Oh1fWz_3BsHb">
<p>At the fist step, for any given input, we have to have evaluation
functions to find the closest visual embedding vector to the input's
textual vectors. We use the Cosine similarity for this operation.</p>
<p><font color='77CC99'>Write a function "visual_embedding_similarity"
to convert input texts to clip embedding vector and then returns the
similarity between the input text and any of the ground truth
images.</font></p>
<p>Note: You can use "get_similarity" function that you have definced
before.</p>
</div>
<div id="IWvYyz6nzHvR" class="cell code" data-execution_count="107"
id="IWvYyz6nzHvR">
<div class="sourceCode" id="cb105"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb105-1"><a href="#cb105-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> visual_embedding_similarity(input_text, caption_embeddings, textual_clip_tokenizer, textual_clip_model):</span>
<span id="cb105-2"><a href="#cb105-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Conversion of input text to CLIP embedding</span></span>
<span id="cb105-3"><a href="#cb105-3" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> textual_clip_tokenizer(input_text, return_tensors<span class="op">=</span><span class="st">&quot;pt&quot;</span>, padding<span class="op">=</span><span class="va">True</span>, truncation<span class="op">=</span><span class="va">True</span>).to(device)</span>
<span id="cb105-4"><a href="#cb105-4" aria-hidden="true" tabindex="-1"></a>    text_embeds <span class="op">=</span> textual_clip_model(<span class="op">**</span>inputs).last_hidden_state.mean(dim<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb105-5"><a href="#cb105-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-6"><a href="#cb105-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Preparation of caption embeddings</span></span>
<span id="cb105-7"><a href="#cb105-7" aria-hidden="true" tabindex="-1"></a>    caption_embeddings <span class="op">=</span> torch.tensor(caption_embeddings).unsqueeze(<span class="dv">0</span>).to(device)</span>
<span id="cb105-8"><a href="#cb105-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-9"><a href="#cb105-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Dimension inspection</span></span>
<span id="cb105-10"><a href="#cb105-10" aria-hidden="true" tabindex="-1"></a>    text_embeds_shape <span class="op">=</span> text_embeds.shape</span>
<span id="cb105-11"><a href="#cb105-11" aria-hidden="true" tabindex="-1"></a>    caption_embeddings_shape <span class="op">=</span> caption_embeddings.shape</span>
<span id="cb105-12"><a href="#cb105-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb105-13"><a href="#cb105-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Calculate similarity with ground truth image captions</span></span>
<span id="cb105-14"><a href="#cb105-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> get_similarity(caption_embeddings, text_embeds, device)</span></code></pre></div>
</div>
<div id="qCd0AKlJC4nu" class="cell markdown" id="qCd0AKlJC4nu">
<p><font color='77CC99'>Now, write a function that finds k most similar
Text/Image to user's input.</font></p>
</div>
<div id="KIf47RTmC-_m" class="cell code" data-execution_count="72"
id="KIf47RTmC-_m">
<div class="sourceCode" id="cb106"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb106-1"><a href="#cb106-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> heapq</span>
<span id="cb106-2"><a href="#cb106-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-3"><a href="#cb106-3" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> multimodal_retrieval(k, input_text, text_embeddings, text_elements, summarized_text_elements,</span>
<span id="cb106-4"><a href="#cb106-4" aria-hidden="true" tabindex="-1"></a>                         text_emb_model, images_embeddings, captions_list, textual_clip_tokenizer, textual_clip_model):</span>
<span id="cb106-5"><a href="#cb106-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-6"><a href="#cb106-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Get text and visual similarities</span></span>
<span id="cb106-7"><a href="#cb106-7" aria-hidden="true" tabindex="-1"></a>    text_similarity <span class="op">=</span> text_embedding_similarity(input_text, text_embeddings, text_emb_model)</span>
<span id="cb106-8"><a href="#cb106-8" aria-hidden="true" tabindex="-1"></a>    visual_similarity <span class="op">=</span> visual_embedding_similarity(input_text, caption_embeddings, textual_clip_tokenizer, textual_clip_model)</span>
<span id="cb106-9"><a href="#cb106-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-10"><a href="#cb106-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve top k indices for text and images</span></span>
<span id="cb106-11"><a href="#cb106-11" aria-hidden="true" tabindex="-1"></a>    top_k_text_indices <span class="op">=</span> heapq.nlargest(k, <span class="bu">range</span>(<span class="bu">len</span>(text_similarity)), text_similarity.take)</span>
<span id="cb106-12"><a href="#cb106-12" aria-hidden="true" tabindex="-1"></a>    top_k_image_indices <span class="op">=</span> heapq.nlargest(k, <span class="bu">range</span>(<span class="bu">len</span>(visual_similarity)), visual_similarity.take)</span>
<span id="cb106-13"><a href="#cb106-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-14"><a href="#cb106-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Select corresponding elements</span></span>
<span id="cb106-15"><a href="#cb106-15" aria-hidden="true" tabindex="-1"></a>    selected_text_elements <span class="op">=</span> [summarized_text_elements[i] <span class="cf">if</span> summarized_text_elements <span class="cf">else</span> text_elements[i] <span class="cf">for</span> i <span class="kw">in</span> top_k_text_indices]</span>
<span id="cb106-16"><a href="#cb106-16" aria-hidden="true" tabindex="-1"></a>    selected_image_elements <span class="op">=</span> [captions_list[i] <span class="cf">for</span> i <span class="kw">in</span> top_k_image_indices]</span>
<span id="cb106-17"><a href="#cb106-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb106-18"><a href="#cb106-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> {<span class="st">&quot;selected_image_elements&quot;</span>: selected_image_elements,</span>
<span id="cb106-19"><a href="#cb106-19" aria-hidden="true" tabindex="-1"></a>            <span class="st">&quot;selected_text_elements&quot;</span>: selected_text_elements}</span></code></pre></div>
</div>
<div id="q0pXU4CFGBBN" class="cell markdown" id="q0pXU4CFGBBN">
<h3 id="step-222-use-the-core-llm-and-combine-them-all">Step 2.2.2: Use
the core LLM and Combine them all</h3>
</div>
<div id="8hFtceV3GHu5" class="cell markdown" id="8hFtceV3GHu5">
<p>In this section, based on what we have done before(Loading LLM), we
want to use what we have done in this section to write the Multimodal
RAG. Do it as follows.</p>
<p><font color='77CC99'> Based on the new prompt which contains both
textual ground truth facts and the caption of visual ground truth
images, to write the "Multimodal_Question_Answering" function. This
function should takes the user's textual question as input, then finds
the most correlated textual and visual ground truth. Then gives them all
to LLM via prompt.</font></p>
</div>
<div id="JNrm8k0fGHdY" class="cell code" data-execution_count="108"
id="JNrm8k0fGHdY">
<div class="sourceCode" id="cb107"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb107-1"><a href="#cb107-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Prompt</span></span>
<span id="cb107-2"><a href="#cb107-2" aria-hidden="true" tabindex="-1"></a>prompt_text <span class="op">=</span> <span class="st">&quot;&quot;&quot;ANSWER the QUESTION in conformity to on FACTS. </span><span class="ch">\n</span></span>
<span id="cb107-3"><a href="#cb107-3" aria-hidden="true" tabindex="-1"></a><span class="st">FACTS: </span><span class="ch">\n</span><span class="st"> </span><span class="sc">{text_facts}</span><span class="st"> </span><span class="ch">\n</span><span class="st"> </span><span class="sc">{image_facts}</span><span class="st">. </span><span class="ch">\n</span></span>
<span id="cb107-4"><a href="#cb107-4" aria-hidden="true" tabindex="-1"></a><span class="st">QUESTION: </span><span class="sc">{user_question}</span><span class="st"> </span><span class="ch">\n</span></span>
<span id="cb107-5"><a href="#cb107-5" aria-hidden="true" tabindex="-1"></a><span class="st">ANSWER:  &quot;&quot;&quot;</span></span></code></pre></div>
</div>
<div id="q9HRbsS79PFU" class="cell code" data-execution_count="132"
id="q9HRbsS79PFU">
<div class="sourceCode" id="cb108"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb108-1"><a href="#cb108-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> LLM(prompt, max_length<span class="op">=</span><span class="dv">180</span>, num_return_sequences<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb108-2"><a href="#cb108-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Tokenize the input prompt</span></span>
<span id="cb108-3"><a href="#cb108-3" aria-hidden="true" tabindex="-1"></a>    inputs <span class="op">=</span> tokenizer(prompt, return_tensors<span class="op">=</span><span class="st">&quot;pt&quot;</span>, padding<span class="op">=</span><span class="va">True</span>, truncation<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb108-4"><a href="#cb108-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-5"><a href="#cb108-5" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Generate response using the model</span></span>
<span id="cb108-6"><a href="#cb108-6" aria-hidden="true" tabindex="-1"></a>    outputs <span class="op">=</span> model.generate(</span>
<span id="cb108-7"><a href="#cb108-7" aria-hidden="true" tabindex="-1"></a>        <span class="op">**</span>inputs,</span>
<span id="cb108-8"><a href="#cb108-8" aria-hidden="true" tabindex="-1"></a>        max_length<span class="op">=</span>max_length,</span>
<span id="cb108-9"><a href="#cb108-9" aria-hidden="true" tabindex="-1"></a>        num_return_sequences<span class="op">=</span>num_return_sequences,</span>
<span id="cb108-10"><a href="#cb108-10" aria-hidden="true" tabindex="-1"></a>        no_repeat_ngram_size<span class="op">=</span><span class="dv">2</span>,</span>
<span id="cb108-11"><a href="#cb108-11" aria-hidden="true" tabindex="-1"></a>        early_stopping<span class="op">=</span><span class="va">True</span></span>
<span id="cb108-12"><a href="#cb108-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb108-13"><a href="#cb108-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-14"><a href="#cb108-14" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Decode the output to text</span></span>
<span id="cb108-15"><a href="#cb108-15" aria-hidden="true" tabindex="-1"></a>    responses <span class="op">=</span> [tokenizer.decode(output, skip_special_tokens<span class="op">=</span><span class="va">True</span>) <span class="cf">for</span> output <span class="kw">in</span> outputs]</span>
<span id="cb108-16"><a href="#cb108-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb108-17"><a href="#cb108-17" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Return the response(s)</span></span>
<span id="cb108-18"><a href="#cb108-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> responses[<span class="dv">0</span>] <span class="cf">if</span> num_return_sequences <span class="op">==</span> <span class="dv">1</span> <span class="cf">else</span> responses</span></code></pre></div>
</div>
<div id="Ma9wLfimHhtW" class="cell code" data-execution_count="133"
id="Ma9wLfimHhtW">
<div class="sourceCode" id="cb109"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb109-1"><a href="#cb109-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> Multimodal_Question_Answering(input_text, k<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb109-2"><a href="#cb109-2" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Retrieve the most correlated textual and visual ground truth</span></span>
<span id="cb109-3"><a href="#cb109-3" aria-hidden="true" tabindex="-1"></a>    retrieval_results <span class="op">=</span> multimodal_retrieval(k, input_text, text_embeddings, text_elements, summarized_text_elements,</span>
<span id="cb109-4"><a href="#cb109-4" aria-hidden="true" tabindex="-1"></a>                                             text_emb_model, images_embeddings, captions_list, textual_clip_tokenizer, textual_clip_model)</span>
<span id="cb109-5"><a href="#cb109-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-6"><a href="#cb109-6" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Combine textual and image facts</span></span>
<span id="cb109-7"><a href="#cb109-7" aria-hidden="true" tabindex="-1"></a>    text_facts <span class="op">=</span> <span class="st">&#39; &#39;</span>.join([el[<span class="st">&#39;summary_text&#39;</span>] <span class="cf">for</span> el <span class="kw">in</span> retrieval_results[<span class="st">&quot;selected_text_elements&quot;</span>]])</span>
<span id="cb109-8"><a href="#cb109-8" aria-hidden="true" tabindex="-1"></a>    image_facts <span class="op">=</span> <span class="st">&#39; &#39;</span>.join([el[<span class="st">&#39;generated_text&#39;</span>] <span class="cf">for</span> el <span class="kw">in</span> retrieval_results[<span class="st">&quot;selected_image_elements&quot;</span>]])</span>
<span id="cb109-9"><a href="#cb109-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-10"><a href="#cb109-10" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Format the prompt</span></span>
<span id="cb109-11"><a href="#cb109-11" aria-hidden="true" tabindex="-1"></a>    prompt <span class="op">=</span> prompt_text.<span class="bu">format</span>(text_facts<span class="op">=</span>text_facts, image_facts<span class="op">=</span>image_facts, user_question<span class="op">=</span>input_text)</span>
<span id="cb109-12"><a href="#cb109-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-13"><a href="#cb109-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># Query the LLM with the new prompt (assuming LLM function is defined)</span></span>
<span id="cb109-14"><a href="#cb109-14" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> LLM(prompt)</span>
<span id="cb109-15"><a href="#cb109-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb109-16"><a href="#cb109-16" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> response</span></code></pre></div>
</div>
<div id="ckWn-6HXH1cN" class="cell code" data-execution_count="134"
id="ckWn-6HXH1cN">
<div class="sourceCode" id="cb110"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb110-1"><a href="#cb110-1" aria-hidden="true" tabindex="-1"></a>input_text <span class="op">=</span> <span class="st">&quot;is DALL-E2 uses a clip model inside?&quot;</span></span>
<span id="cb110-2"><a href="#cb110-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb110-3"><a href="#cb110-3" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> Multimodal_Question_Answering(input_text,k<span class="op">=</span><span class="dv">1</span>)</span></code></pre></div>
</div>
<div id="yYXhGZExIBjk" class="cell code" data-execution_count="135"
data-colab="{&quot;base_uri&quot;:&quot;https://localhost:8080/&quot;,&quot;height&quot;:107}"
id="yYXhGZExIBjk" data-outputId="77338e4f-f942-47c5-8406-31d5298eb946">
<div class="sourceCode" id="cb111"><pre
class="sourceCode python"><code class="sourceCode python"><span id="cb111-1"><a href="#cb111-1" aria-hidden="true" tabindex="-1"></a>response</span></code></pre></div>
<div class="output execute_result" data-execution_count="135">
<div class="sourceCode" id="cb112"><pre
class="sourceCode json"><code class="sourceCode json"><span id="cb112-1"><a href="#cb112-1" aria-hidden="true" tabindex="-1"></a><span class="fu">{</span><span class="dt">&quot;type&quot;</span><span class="fu">:</span><span class="st">&quot;string&quot;</span><span class="fu">}</span></span></code></pre></div>
</div>
</div>
<div id="uBAo_j4aPEBa" class="cell markdown" id="uBAo_j4aPEBa">
<p><font color='77CC99'>The Answer to the input question is "Yes" or
"No". What are your Semi-structured models' answers? (Both Unimodal and
Multimodal). Are they right or not?</font></p>
</div>
<div id="z9xbW4lbPqKs" class="cell markdown" id="z9xbW4lbPqKs">
<p><font color='CC7799'>Your Answer:</font></p>
</div>
<div id="f5Jb5GXVPyL9" class="cell markdown" id="f5Jb5GXVPyL9">
<p>Unimodal: NO (It <strong>doesn't give</strong> a direct answer in
it's output)</p>
<p>Multimodal: NO (It gives <strong>A WRONG</strong> answer)</p>
<p><strong>The Unimodal Does't Output Relevant Answer:</strong></p>
<p>"Since its release, CLIP has been used extensively to steer
generative image models towards text prompts. Nichol et al. [35] showed
classiﬁer-free guidance works more favorably than CLIP guidance for text
conditional image generation. Zhou and Crowson [9] trained diffusion
models conditioned on CLIP text embeddings, allowing for direct
text-conditional imagegeneration."</p>
<p><strong>The multi-modal RAG Outputs Incorrect Answer:</strong></p>
<p>"ANSWER the QUESTION in conformity to on FACTS. \n\nFACTS: \n Since
its release, CLIP has been used extensively to steer generative image
models towards text prompts. Nichol et al. [35] showed classiﬁer-free
guidance works more favorably than CLIP guidance for text conditional
image generation. Zhou and Crowson [9] trained diffusion models
conditioned on CLIP text embeddings, allowing for direct
text-conditional imagegeneration. \n a person holding a green plant in
their hand . \n\nQUESTION: is DALL-E2 uses a clip model inside?
\n\nANSWER: \nDALL E2-is used to train a model, but it is not a part of
the model itself.\nThe model"</p>
<p><strong>The Actual Answer</strong>: (Inshallah GPT-3.5 actually knows
about OpenAI stuff)</p>
<p>"Yes, DALL-E 2 uses a CLIP model as part of its architecture. DALL-E
2, developed by OpenAI, is an advanced AI model designed for generating
images from textual descriptions. One of its key components is the CLIP
(Contrastive Language–Image Pretraining) model, also developed by
OpenAI."</p>
</div>
